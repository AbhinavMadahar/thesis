% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Zellers2019-gw,
  title         = "{HellaSwag}: Can a Machine Really Finish Your Sentence?",
  author        = "Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and
                   Farhadi, Ali and Choi, Yejin",
  abstract      = "Recent work by Zellers et al. (2018) introduced a new task
                   of commonsense natural language inference: given an event
                   description such as ``A woman sits at a piano,'' a machine
                   must select the most likely followup: ``She sets her fingers
                   on the keys.'' With the introduction of BERT, near
                   human-level performance was reached. Does this mean that
                   machines can perform human level commonsense inference? In
                   this paper, we show that commonsense inference still proves
                   difficult for even state-of-the-art models, by presenting
                   HellaSwag, a new challenge dataset. Though its questions are
                   trivial for humans (>95\% accuracy), state-of-the-art models
                   struggle (<48\%). We achieve this via Adversarial Filtering
                   (AF), a data collection paradigm wherein a series of
                   discriminators iteratively select an adversarial set of
                   machine-generated wrong answers. AF proves to be
                   surprisingly robust. The key insight is to scale up the
                   length and complexity of the dataset examples towards a
                   critical 'Goldilocks' zone wherein generated text is
                   ridiculous to humans, yet often misclassified by
                   state-of-the-art models. Our construction of HellaSwag, and
                   its resulting difficulty, sheds light on the inner workings
                   of deep pretrained models. More broadly, it suggests a new
                   path forward for NLP research, in which benchmarks co-evolve
                   with the evolving state-of-the-art in an adversarial way, so
                   as to present ever-harder challenges.",
  month         =  may,
  year          =  2019,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1905.07830"
}

@ARTICLE{Clark2018-md,
  title         = "Think you have Solved Question Answering? Try {ARC}, the
                   {AI2} Reasoning Challenge",
  author        = "Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot,
                   Tushar and Sabharwal, Ashish and Schoenick, Carissa and
                   Tafjord, Oyvind",
  abstract      = "We present a new question set, text corpus, and baselines
                   assembled to encourage AI research in advanced question
                   answering. Together, these constitute the AI2 Reasoning
                   Challenge (ARC), which requires far more powerful knowledge
                   and reasoning than previous challenges such as SQuAD or
                   SNLI. The ARC question set is partitioned into a Challenge
                   Set and an Easy Set, where the Challenge Set contains only
                   questions answered incorrectly by both a retrieval-based
                   algorithm and a word co-occurence algorithm. The dataset
                   contains only natural, grade-school science questions
                   (authored for human tests), and is the largest public-domain
                   set of this kind (7,787 questions). We test several
                   baselines on the Challenge Set, including leading neural
                   models from the SQuAD and SNLI tasks, and find that none are
                   able to significantly outperform a random baseline,
                   reflecting the difficult nature of this task. We are also
                   releasing the ARC Corpus, a corpus of 14M science sentences
                   relevant to the task, and implementations of the three
                   neural baseline models tested. Can your model perform
                   better? We pose ARC as a challenge to the community.",
  month         =  mar,
  year          =  2018,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "1803.05457"
}

@ARTICLE{Liu2021-iq,
  title         = "Generated Knowledge Prompting for Commonsense Reasoning",
  author        = "Liu, Jiacheng and Liu, Alisa and Lu, Ximing and Welleck,
                   Sean and West, Peter and Le Bras, Ronan and Choi, Yejin and
                   Hajishirzi, Hannaneh",
  abstract      = "It remains an open question whether incorporating external
                   knowledge benefits commonsense reasoning while maintaining
                   the flexibility of pretrained sequence models. To
                   investigate this question, we develop generated knowledge
                   prompting, which consists of generating knowledge from a
                   language model, then providing the knowledge as additional
                   input when answering a question. Our method does not require
                   task-specific supervision for knowledge integration, or
                   access to a structured knowledge base, yet it improves
                   performance of large-scale, state-of-the-art models on four
                   commonsense reasoning tasks, achieving state-of-the-art
                   results on numerical commonsense (NumerSense), general
                   commonsense (CommonsenseQA 2.0), and scientific commonsense
                   (QASC) benchmarks. Generated knowledge prompting highlights
                   large-scale language models as flexible sources of external
                   knowledge for improving commonsense reasoning. Our code is
                   available at https://github.com/liujch1998/GKP",
  month         =  oct,
  year          =  2021,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2110.08387"
}

@ARTICLE{Bian2023-rj,
  title         = "{ChatGPT} is a Knowledgeable but Inexperienced Solver: An
                   Investigation of Commonsense Problem in Large Language
                   Models",
  author        = "Bian, Ning and Han, Xianpei and Sun, Le and Lin, Hongyu and
                   Lu, Yaojie and He, Ben",
  abstract      = "Large language models (LLMs) such as ChatGPT and GPT-4 have
                   made significant progress in NLP. However, their ability to
                   memorize, represent, and leverage commonsense knowledge has
                   been a well-known pain point for LLMs. It remains unclear
                   that: (1) Can GPTs effectively answer commonsense questions?
                   (2) Are GPTs knowledgeable in commonsense? (3) Are GPTs
                   aware of the underlying commonsense knowledge for answering
                   a specific question? (4) Can GPTs effectively leverage
                   commonsense for answering questions? To evaluate the above
                   commonsense problems, we conduct a series of experiments to
                   evaluate ChatGPT's commonsense abilities, and the
                   experimental results show that: (1) GPTs can achieve good QA
                   accuracy in commonsense tasks, while they still struggle
                   with certain types of knowledge. (2) ChatGPT is
                   knowledgeable, and can accurately generate most of the
                   commonsense knowledge using knowledge prompts. (3) Despite
                   its knowledge, ChatGPT is an inexperienced commonsense
                   problem solver, which cannot precisely identify the needed
                   commonsense knowledge for answering a specific question,
                   i.e., ChatGPT does not precisely know what commonsense
                   knowledge is required to answer a question. The above
                   findings raise the need to investigate better mechanisms for
                   utilizing commonsense knowledge in LLMs, such as instruction
                   following, better commonsense guidance, etc.",
  month         =  mar,
  year          =  2023,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2303.16421"
}

@ARTICLE{Bouraoui2020-fw,
  title    = "Inducing Relational Knowledge from {BERT}",
  author   = "Bouraoui, Zied and Camacho-Collados, Jose and Schockaert, Steven",
  journal  = "AAAI",
  volume   =  34,
  number   =  05,
  pages    = "7456--7463",
  month    =  apr,
  year     =  2020,
  keywords = "thesis/prior work",
  language = "en"
}

@ARTICLE{Feldman2019-gc,
  title         = "Commonsense Knowledge Mining from Pretrained Models",
  author        = "Feldman, Joshua and Davison, Joe and Rush, Alexander M",
  abstract      = "Inferring commonsense knowledge is a key challenge in
                   natural language processing, but due to the sparsity of
                   training data, previous work has shown that supervised
                   methods for commonsense knowledge mining underperform when
                   evaluated on novel data. In this work, we develop a method
                   for generating commonsense knowledge using a large,
                   pre-trained bidirectional language model. By transforming
                   relational triples into masked sentences, we can use this
                   model to rank a triple's validity by the estimated pointwise
                   mutual information between the two entities. Since we do not
                   update the weights of the bidirectional model, our approach
                   is not biased by the coverage of any one commonsense
                   knowledge base. Though this method performs worse on a test
                   set than models explicitly trained on a corresponding
                   training set, it outperforms these methods when mining
                   commonsense knowledge from new sources, suggesting that
                   unsupervised techniques may generalize better than current
                   supervised approaches.",
  month         =  sep,
  year          =  2019,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1909.00505"
}

@ARTICLE{Petroni2019-uz,
  title         = "Language Models as Knowledge Bases?",
  author        = "Petroni, Fabio and Rockt{\"a}schel, Tim and Lewis, Patrick
                   and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H
                   and Riedel, Sebastian",
  abstract      = "Recent progress in pretraining language models on large
                   textual corpora led to a surge of improvements for
                   downstream NLP tasks. Whilst learning linguistic knowledge,
                   these models may also be storing relational knowledge
                   present in the training data, and may be able to answer
                   queries structured as ``fill-in-the-blank'' cloze
                   statements. Language models have many advantages over
                   structured knowledge bases: they require no schema
                   engineering, allow practitioners to query about an open
                   class of relations, are easy to extend to more data, and
                   require no human supervision to train. We present an
                   in-depth analysis of the relational knowledge already
                   present (without fine-tuning) in a wide range of
                   state-of-the-art pretrained language models. We find that
                   (i) without fine-tuning, BERT contains relational knowledge
                   competitive with traditional NLP methods that have some
                   access to oracle knowledge, (ii) BERT also does remarkably
                   well on open-domain question answering against a supervised
                   baseline, and (iii) certain types of factual knowledge are
                   learned much more readily than others by standard language
                   model pretraining approaches. The surprisingly strong
                   ability of these models to recall factual knowledge without
                   any fine-tuning demonstrates their potential as unsupervised
                   open-domain QA systems. The code to reproduce our analysis
                   is available at https://github.com/facebookresearch/LAMA.",
  month         =  sep,
  year          =  2019,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1909.01066"
}

@MISC{Council_of_Graduate_Schools2021-qf,
  title        = "April 15 Resolution",
  booktitle    = "{CGS}",
  author       = "{Council of Graduate Schools}",
  abstract     = "April 15 Resolution gives applicants to April 15 to consider
                  graduate admission offers that include financial support at
                  signatory schools.",
  month        =  dec,
  year         =  2021,
  howpublished = "\url{https://cgsnet.org/resources/for-current-prospective-graduate-students/april-15-resolution}",
  note         = "Accessed: 2023-12-13",
  keywords     = "thesis/prior work",
  language     = "en"
}

@MISC{Vrajitoru_undated-xc,
  title        = "Embarrassingly Parallel Programs",
  author       = "Vrajitoru, Dana",
  howpublished = "\url{https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html}",
  note         = "Accessed: 2023-12-13",
  keywords     = "thesis/prior work"
}

@ARTICLE{Calijorne_Soares2020-eo,
  title    = "A literature review on question answering techniques, paradigms
              and systems",
  author   = "Calijorne Soares, Marco Antonio and Parreiras, Fernando Silva",
  abstract = "Background Question Answering (QA) systems enable users to
              retrieve exact answers for questions posed in natural language.
              Objective This study aims at identifying QA techniques, tools and
              systems, as well as the metrics and indicators used to measure
              these approaches for QA systems and also to determine how the
              relationship between Question Answering and natural language
              processing is built. Method The method adopted was a Systematic
              Literature Review of studies published from 2000 to 2017. Results
              130 out of 1842 papers have been identified as describing a QA
              approach developed and evaluated with different techniques.
              Conclusion Question Answering researchers have concentrated their
              efforts in natural language processing, knowledge base and
              information retrieval paradigms. Most of the researches focused
              on open domain. Regarding the metrics used to evaluate the
              approaches, Precision and Recall are the most addressed.",
  journal  = "Journal of King Saud University - Computer and Information
              Sciences",
  volume   =  32,
  number   =  6,
  pages    = "635--646",
  month    =  jul,
  year     =  2020,
  keywords = "Question answering systems; Natural language processing;
              Information retrieval;thesis/prior work"
}

@ARTICLE{Li2016-ef,
  title         = "Deep Reinforcement Learning for Dialogue Generation",
  author        = "Li, Jiwei and Monroe, Will and Ritter, Alan and Galley,
                   Michel and Gao, Jianfeng and Jurafsky, Dan",
  abstract      = "Recent neural models of dialogue generation offer great
                   promise for generating responses for conversational agents,
                   but tend to be shortsighted, predicting utterances one at a
                   time while ignoring their influence on future outcomes.
                   Modeling the future direction of a dialogue is crucial to
                   generating coherent, interesting dialogues, a need which led
                   traditional NLP models of dialogue to draw on reinforcement
                   learning. In this paper, we show how to integrate these
                   goals, applying deep reinforcement learning to model future
                   reward in chatbot dialogue. The model simulates dialogues
                   between two virtual agents, using policy gradient methods to
                   reward sequences that display three useful conversational
                   properties: informativity (non-repetitive turns), coherence,
                   and ease of answering (related to forward-looking function).
                   We evaluate our model on diversity, length as well as with
                   human judges, showing that the proposed algorithm generates
                   more interactive responses and manages to foster a more
                   sustained conversation in dialogue simulation. This work
                   marks a first step towards learning a neural conversational
                   model based on the long-term success of dialogues.",
  month         =  jun,
  year          =  2016,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1606.01541"
}

@INPROCEEDINGS{Zellers2019-to,
  title           = "From recognition to cognition: Visual commonsense
                     reasoning",
  booktitle       = "2019 {IEEE/CVF} Conference on Computer Vision and Pattern
                     Recognition ({CVPR})",
  author          = "Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and
                     Choi, Yejin",
  publisher       = "IEEE",
  month           =  jun,
  year            =  2019,
  keywords        = "commonsense reasoning;thesis/prior work",
  conference      = "2019 IEEE/CVF Conference on Computer Vision and Pattern
                     Recognition (CVPR)",
  location        = "Long Beach, CA, USA"
}

@ARTICLE{Martinez_del_Rincon2013-qo,
  title    = "Common-sense reasoning for human action recognition",
  author   = "Mart{\'\i}nez del Rinc{\'o}n, Jes{\'u}s and Santofimia, Maria J
              and Nebel, Jean-Christophe",
  abstract = "This paper presents a novel method that leverages reasoning
              capabilities in a computer vision system dedicated to human
              action recognition. The proposed methodology is decomposed into
              two stages. First, a machine learning based algorithm -- known as
              bag of words -- gives a first estimate of action classification
              from video sequences, by performing an image feature analysis.
              Those results are afterward passed to a common-sense reasoning
              system, which analyses, selects and corrects the initial
              estimation yielded by the machine learning algorithm. This second
              stage resorts to the knowledge implicit in the rationality that
              motivates human behaviour. Experiments are performed in realistic
              conditions, where poor recognition rates by the machine learning
              techniques are significantly improved by the second stage in
              which common-sense knowledge and reasoning capabilities have been
              leveraged. This demonstrates the value of integrating
              common-sense capabilities into a computer vision pipeline.",
  journal  = "Pattern Recognit. Lett.",
  volume   =  34,
  number   =  15,
  pages    = "1849--1860",
  month    =  nov,
  year     =  2013,
  keywords = "Common sense; Artificial intelligence; Action recognition; Bag of
              words; Computer vision;commonsense reasoning;thesis/prior work"
}

@ARTICLE{Bubeck2023-gl,
  title         = "Sparks of Artificial General Intelligence: Early experiments
                   with {GPT-4}",
  author        = "Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan,
                   Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece
                   and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and
                   Lundberg, Scott and Nori, Harsha and Palangi, Hamid and
                   Ribeiro, Marco Tulio and Zhang, Yi",
  abstract      = "Artificial intelligence (AI) researchers have been
                   developing and refining large language models (LLMs) that
                   exhibit remarkable capabilities across a variety of domains
                   and tasks, challenging our understanding of learning and
                   cognition. The latest model developed by OpenAI, GPT-4, was
                   trained using an unprecedented scale of compute and data. In
                   this paper, we report on our investigation of an early
                   version of GPT-4, when it was still in active development by
                   OpenAI. We contend that (this early version of) GPT-4 is
                   part of a new cohort of LLMs (along with ChatGPT and
                   Google's PaLM for example) that exhibit more general
                   intelligence than previous AI models. We discuss the rising
                   capabilities and implications of these models. We
                   demonstrate that, beyond its mastery of language, GPT-4 can
                   solve novel and difficult tasks that span mathematics,
                   coding, vision, medicine, law, psychology and more, without
                   needing any special prompting. Moreover, in all of these
                   tasks, GPT-4's performance is strikingly close to
                   human-level performance, and often vastly surpasses prior
                   models such as ChatGPT. Given the breadth and depth of
                   GPT-4's capabilities, we believe that it could reasonably be
                   viewed as an early (yet still incomplete) version of an
                   artificial general intelligence (AGI) system. In our
                   exploration of GPT-4, we put special emphasis on discovering
                   its limitations, and we discuss the challenges ahead for
                   advancing towards deeper and more comprehensive versions of
                   AGI, including the possible need for pursuing a new paradigm
                   that moves beyond next-word prediction. We conclude with
                   reflections on societal influences of the recent
                   technological leap and future research directions.",
  month         =  mar,
  year          =  2023,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2303.12712"
}

@ARTICLE{Wei2022-nf,
  title         = "Chain-of-thought prompting elicits reasoning in large
                   language models",
  author        = "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma,
                   Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le,
                   Quoc and Zhou, Denny",
  abstract      = "We explore how generating a chain of thought -- a series of
                   intermediate reasoning steps -- significantly improves the
                   ability of large language models to perform complex
                   reasoning. In particular, we show how such reasoning
                   abilities emerge naturally in sufficiently large language
                   models via a simple method called chain of thought
                   prompting, where a few chain of thought demonstrations are
                   provided as exemplars in prompting. Experiments on three
                   large language models show that chain of thought prompting
                   improves performance on a range of arithmetic, commonsense,
                   and symbolic reasoning tasks. The empirical gains can be
                   striking. For instance, prompting a 540B-parameter language
                   model with just eight chain of thought exemplars achieves
                   state of the art accuracy on the GSM8K benchmark of math
                   word problems, surpassing even finetuned GPT-3 with a
                   verifier.",
  month         =  jan,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2201.11903"
}

@ARTICLE{Rajani2019-zk,
  title         = "Explain Yourself! Leveraging Language Models for Commonsense
                   Reasoning",
  author        = "Rajani, Nazneen Fatema and McCann, Bryan and Xiong, Caiming
                   and Socher, Richard",
  abstract      = "Deep learning models perform poorly on tasks that require
                   commonsense reasoning, which often necessitates some form of
                   world-knowledge or reasoning over information not
                   immediately present in the input. We collect human
                   explanations for commonsense reasoning in the form of
                   natural language sequences and highlighted annotations in a
                   new dataset called Common Sense Explanations (CoS-E). We use
                   CoS-E to train language models to automatically generate
                   explanations that can be used during training and inference
                   in a novel Commonsense Auto-Generated Explanation (CAGE)
                   framework. CAGE improves the state-of-the-art by 10\% on the
                   challenging CommonsenseQA task. We further study commonsense
                   reasoning in DNNs using both human and auto-generated
                   explanations including transfer to out-of-domain tasks.
                   Empirical results indicate that we can effectively leverage
                   language models for commonsense reasoning.",
  month         =  jun,
  year          =  2019,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1906.02361"
}

@UNPUBLISHED{Trinh2018-pm,
  title    = "Do Language Models Have Common Sense?",
  author   = "Trinh, Trieu H and Le, Quoc V",
  abstract = "It has been argued that current machine learning models do not
              have commonsense, and therefore must be hard-coded with prior
              knowledge (Marcus, 2018). Here we show surprising evidence that
              language models can already learn to capture certain common sense
              knowledge. Our key observation is that a language model can
              compute the probability of any statement, and this probability
              can be used to evaluate the truthfulness of that statement. On
              the Winograd Schema Challenge (Levesque et al., 2011), language
              models are 11\% higher in accuracy than previous state-of-the-art
              supervised methods. Language models can also be fine-tuned for
              the task of Mining Commonsense Knowledge on ConceptNet to achieve
              an F1 score of 0.912 and 0.824, outperforming previous best
              results (Jastrzebskiet al., 2018). Further analysis demonstrates
              that language models can discover unique features of Winograd
              Schema contexts that decide the correct answers without explicit
              supervision.",
  month    =  sep,
  year     =  2018,
  keywords = "commonsense reasoning;thesis/prior work"
}

@ARTICLE{Zhou2020-wi,
  title    = "Evaluating Commonsense in {Pre-Trained} Language Models",
  author   = "Zhou, Xuhui and Zhang, Yue and Cui, Leyang and Huang, Dandan",
  abstract = "Contextualized representations trained over large raw text data
              have given remarkable improvements for NLP tasks including
              question answering and reading comprehension. There have been
              works showing that syntactic, semantic and word sense knowledge
              are contained in such representations, which explains why they
              benefit such tasks. However, relatively little work has been done
              investigating commonsense knowledge contained in contextualized
              representations, which is crucial for human question answering
              and reading comprehension. We study the commonsense ability of
              GPT, BERT, XLNet, and RoBERTa by testing them on seven
              challenging benchmarks, finding that language modeling and its
              variants are effective objectives for promoting models'
              commonsense ability while bi-directional context and larger
              training set are bonuses. We additionally find that current
              models do poorly on tasks require more necessary inference steps.
              Finally, we test the robustness of models by making dual test
              cases, which are correlated so that the correct prediction of one
              sample should lead to correct prediction of the other.
              Interestingly, the models show confusion on these test cases,
              which suggests that they learn commonsense at the surface rather
              than the deep level. We release a test set, named CATs publicly,
              for future research.",
  journal  = "AAAI",
  volume   =  34,
  number   =  05,
  pages    = "9733--9740",
  month    =  apr,
  year     =  2020,
  keywords = "commonsense reasoning;thesis/prior work",
  language = "en"
}

@MISC{Cham2006-zx,
  title    = "Your Thesis Title",
  author   = "Cham, Jorge",
  year     =  2006,
  keywords = "thesis/prior work"
}

@MISC{Rahimi2017-ax,
  title        = "Back When We Were Kids",
  author       = "Rahimi, Ali",
  month        =  dec,
  year         =  2017,
  howpublished = "NeurIPS",
  keywords     = "thesis/prior work",
  location     = "Long Beach, California, US"
}

@MISC{Jonze2013-pk,
  title     = "Her",
  author    = "Jonze, Spike",
  publisher = "Annapurna Pictures",
  month     =  oct,
  year      =  2013,
  address   = "United States",
  keywords  = "thesis/prior work"
}

@ARTICLE{Nagel1974-dv,
  title     = "What is it like to be a bat?",
  author    = "Nagel, Thomas",
  journal   = "Philos. Rev.",
  publisher = "JSTOR",
  volume    =  83,
  number    =  4,
  pages     = "435",
  month     =  oct,
  year      =  1974,
  keywords  = "machine consciousness;thesis/prior work"
}

@ARTICLE{Francken2022-uk,
  title    = "An academic survey on theoretical foundations, common assumptions
              and the current state of consciousness science",
  author   = "Francken, Jolien C and Beerendonk, Lola and Molenaar, Dylan and
              Fahrenfort, Johannes J and Kiverstein, Julian D and Seth, Anil K
              and van Gaal, Simon",
  abstract = "We report the results of an academic survey into the theoretical
              and methodological foundations, common assumptions, and the
              current state of the field of consciousness research. The survey
              consisted of 22 questions and was distributed on two different
              occasions of the annual meeting of the Association of the
              Scientific Study of Consciousness (2018 and 2019). We examined
              responses from 166 consciousness researchers with different
              backgrounds (e.g. philosophy, neuroscience, psychology, and
              computer science) and at various stages of their careers (e.g.
              junior/senior faculty and graduate/undergraduate students). The
              results reveal that there remains considerable discussion and
              debate between the surveyed researchers about the definition of
              consciousness and the way it should be studied. To highlight a
              few observations, a majority of respondents believe that machines
              could have consciousness, that consciousness is a gradual
              phenomenon in the animal kingdom, and that unconscious processing
              is extensive, encompassing both low-level and high-level
              cognitive functions. Further, we show which theories of
              consciousness are currently considered most promising by
              respondents and how supposedly different theories cluster
              together, which dependent measures are considered best to index
              the presence or absence of consciousness, and which neural
              measures are thought to be the most likely signatures of
              consciousness. These findings provide us with a snapshot of the
              current views of researchers in the field and may therefore help
              prioritize research and theoretical approaches to foster
              progress.",
  journal  = "Neurosci Conscious",
  volume   =  2022,
  number   =  1,
  pages    = "niac011",
  month    =  aug,
  year     =  2022,
  keywords = "ASSC; consciousness; definitions; survey;thesis/prior work",
  language = "en"
}

@ARTICLE{Perez2023-yd,
  title         = "Towards Evaluating {AI} Systems for Moral Status Using
                   {Self-Reports}",
  author        = "Perez, Ethan and Long, Robert",
  abstract      = "As AI systems become more advanced and widely deployed,
                   there will likely be increasing debate over whether AI
                   systems could have conscious experiences, desires, or other
                   states of potential moral significance. It is important to
                   inform these discussions with empirical evidence to the
                   extent possible. We argue that under the right
                   circumstances, self-reports, or an AI system's statements
                   about its own internal states, could provide an avenue for
                   investigating whether AI systems have states of moral
                   significance. Self-reports are the main way such states are
                   assessed in humans (``Are you in pain?''), but self-reports
                   from current systems like large language models are spurious
                   for many reasons (e.g. often just reflecting what humans
                   would say). To make self-reports more appropriate for this
                   purpose, we propose to train models to answer many kinds of
                   questions about themselves with known answers, while
                   avoiding or limiting training incentives that bias
                   self-reports. The hope of this approach is that models will
                   develop introspection-like capabilities, and that these
                   capabilities will generalize to questions about states of
                   moral significance. We then propose methods for assessing
                   the extent to which these techniques have succeeded:
                   evaluating self-report consistency across contexts and
                   between similar models, measuring the confidence and
                   resilience of models' self-reports, and using
                   interpretability to corroborate self-reports. We also
                   discuss challenges for our approach, from philosophical
                   difficulties in interpreting self-reports to technical
                   reasons why our proposal might fail. We hope our discussion
                   inspires philosophers and AI researchers to criticize and
                   improve our proposed methodology, as well as to run
                   experiments to test whether self-reports can be made
                   reliable enough to provide information about states of moral
                   significance.",
  month         =  nov,
  year          =  2023,
  keywords      = "machine consciousness;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2311.08576"
}

@ARTICLE{Hinton2015-bf,
  title         = "Distilling the Knowledge in a Neural Network",
  author        = "Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff",
  abstract      = "A very simple way to improve the performance of almost any
                   machine learning algorithm is to train many different models
                   on the same data and then to average their predictions.
                   Unfortunately, making predictions using a whole ensemble of
                   models is cumbersome and may be too computationally
                   expensive to allow deployment to a large number of users,
                   especially if the individual models are large neural nets.
                   Caruana and his collaborators have shown that it is possible
                   to compress the knowledge in an ensemble into a single model
                   which is much easier to deploy and we develop this approach
                   further using a different compression technique. We achieve
                   some surprising results on MNIST and we show that we can
                   significantly improve the acoustic model of a heavily used
                   commercial system by distilling the knowledge in an ensemble
                   of models into a single model. We also introduce a new type
                   of ensemble composed of one or more full models and many
                   specialist models which learn to distinguish fine-grained
                   classes that the full models confuse. Unlike a mixture of
                   experts, these specialist models can be trained rapidly and
                   in parallel.",
  month         =  mar,
  year          =  2015,
  keywords      = "reading list;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "1503.02531"
}

@ARTICLE{Shwartz2020-bm,
  title         = "Unsupervised Commonsense Question Answering with {Self-Talk}",
  author        = "Shwartz, Vered and West, Peter and Le Bras, Ronan and
                   Bhagavatula, Chandra and Choi, Yejin",
  abstract      = "Natural language understanding involves reading between the
                   lines with implicit background knowledge. Current systems
                   either rely on pre-trained language models as the sole
                   implicit source of world knowledge, or resort to external
                   knowledge bases (KBs) to incorporate additional relevant
                   knowledge. We propose an unsupervised framework based on
                   self-talk as a novel alternative to multiple-choice
                   commonsense tasks. Inspired by inquiry-based discovery
                   learning (Bruner, 1961), our approach inquires language
                   models with a number of information seeking questions such
                   as ``$\textit\{what is the definition of ...\}$'' to
                   discover additional background knowledge. Empirical results
                   demonstrate that the self-talk procedure substantially
                   improves the performance of zero-shot language model
                   baselines on four out of six commonsense benchmarks, and
                   competes with models that obtain knowledge from external
                   KBs. While our approach improves performance on several
                   benchmarks, the self-talk induced knowledge even when
                   leading to correct answers is not always seen as useful by
                   human judges, raising interesting questions about the
                   inner-workings of pre-trained language models for
                   commonsense reasoning.",
  month         =  apr,
  year          =  2020,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2004.05483"
}

@ARTICLE{Zhou2021-iy,
  title         = "Think Before You Speak: Explicitly Generating Implicit
                   Commonsense Knowledge for Response Generation",
  author        = "Zhou, Pei and Gopalakrishnan, Karthik and Hedayatnia, Behnam
                   and Kim, Seokhwan and Pujara, Jay and Ren, Xiang and Liu,
                   Yang and Hakkani-Tur, Dilek",
  abstract      = "Implicit knowledge, such as common sense, is key to fluid
                   human conversations. Current neural response generation (RG)
                   models are trained to generate responses directly, omitting
                   unstated implicit knowledge. In this paper, we present
                   Think-Before-Speaking (TBS), a generative approach to first
                   externalize implicit commonsense knowledge (think) and use
                   this knowledge to generate responses (speak). We expect that
                   externalizing implicit knowledge allows more efficient
                   learning, produces more informative responses, and enables
                   more explainable models. We analyze different choices to
                   collect knowledge-aligned dialogues, represent implicit
                   knowledge, and transition between knowledge and dialogues.
                   Empirical results show TBS models outperform end-to-end and
                   knowledge-augmented RG baselines on most automatic metrics
                   and generate more informative, specific, and
                   commonsense-following responses, as evaluated by human
                   annotators. TBS also generates knowledge that makes sense
                   and is relevant to the dialogue around 85\% of the time.",
  month         =  oct,
  year          =  2021,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2110.08501"
}

@ARTICLE{Speer2017-vu,
  title         = "{ConceptNet} 5.5: An Open Multilingual Graph of General
                   Knowledge",
  author        = "Speer, Robyn and Chin, Joshua and Havasi, Catherine",
  abstract      = "Machine learning about language can be improved by supplying
                   it with specific knowledge and sources of external
                   information. We present here a new version of the linked
                   open data resource ConceptNet that is particularly well
                   suited to be used with modern NLP techniques such as word
                   embeddings. ConceptNet is a knowledge graph that connects
                   words and phrases of natural language with labeled edges.
                   Its knowledge is collected from many sources that include
                   expert-created resources, crowd-sourcing, and games with a
                   purpose. It is designed to represent the general knowledge
                   involved in understanding language, improving natural
                   language applications by allowing the application to better
                   understand the meanings behind the words people use. When
                   ConceptNet is combined with word embeddings acquired from
                   distributional semantics (such as word2vec), it provides
                   applications with understanding that they would not acquire
                   from distributional semantics alone, nor from narrower
                   resources such as WordNet or DBPedia. We demonstrate this
                   with state-of-the-art results on intrinsic evaluations of
                   word relatedness that translate into improvements on
                   applications of word vectors, including solving SAT-style
                   analogies.",
  number        =  1,
  month         =  feb,
  year          =  2017,
  keywords      = "ConceptNet; knowledge graph; word embeddings;commonsense
                   reasoning;thesis/prior work",
  language      = "en",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1612.03975"
}

@ARTICLE{Zhong2019-gv,
  title         = "{Knowledge-Enriched} Transformer for Emotion Detection in
                   Textual Conversations",
  author        = "Zhong, Peixiang and Wang, Di and Miao, Chunyan",
  abstract      = "Messages in human conversations inherently convey emotions.
                   The task of detecting emotions in textual conversations
                   leads to a wide range of applications such as opinion mining
                   in social networks. However, enabling machines to analyze
                   emotions in conversations is challenging, partly because
                   humans often rely on the context and commonsense knowledge
                   to express emotions. In this paper, we address these
                   challenges by proposing a Knowledge-Enriched Transformer
                   (KET), where contextual utterances are interpreted using
                   hierarchical self-attention and external commonsense
                   knowledge is dynamically leveraged using a context-aware
                   affective graph attention mechanism. Experiments on multiple
                   textual conversation datasets demonstrate that both context
                   and commonsense knowledge are consistently beneficial to the
                   emotion detection performance. In addition, the experimental
                   results show that our KET model outperforms the
                   state-of-the-art models on most of the tested datasets in F1
                   score.",
  month         =  sep,
  year          =  2019,
  keywords      = "need to include in proposal outline;commonsense
                   reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1909.10681"
}

@ARTICLE{Li2017-tj,
  title         = "{DailyDialog}: A Manually Labelled Multi-turn Dialogue
                   Dataset",
  author        = "Li, Yanran and Su, Hui and Shen, Xiaoyu and Li, Wenjie and
                   Cao, Ziqiang and Niu, Shuzi",
  abstract      = "We develop a high-quality multi-turn dialog dataset,
                   DailyDialog, which is intriguing in several aspects. The
                   language is human-written and less noisy. The dialogues in
                   the dataset reflect our daily communication way and cover
                   various topics about our daily life. We also manually label
                   the developed dataset with communication intention and
                   emotion information. Then, we evaluate existing approaches
                   on DailyDialog dataset and hope it benefit the research
                   field of dialog systems.",
  month         =  oct,
  year          =  2017,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1710.03957"
}

@ARTICLE{Poria2020-xk,
  title         = "Recognizing Emotion Cause in Conversations",
  author        = "Poria, Soujanya and Majumder, Navonil and Hazarika,
                   Devamanyu and Ghosal, Deepanway and Bhardwaj, Rishabh and
                   Jian, Samson Yu Bai and Hong, Pengfei and Ghosh, Romila and
                   Roy, Abhinaba and Chhaya, Niyati and Gelbukh, Alexander and
                   Mihalcea, Rada",
  abstract      = "We address the problem of recognizing emotion cause in
                   conversations, define two novel sub-tasks of this problem,
                   and provide a corresponding dialogue-level dataset, along
                   with strong Transformer-based baselines. The dataset is
                   available at https://github.com/declare-lab/RECCON.
                   Introduction: Recognizing the cause behind emotions in text
                   is a fundamental yet under-explored area of research in NLP.
                   Advances in this area hold the potential to improve
                   interpretability and performance in affect-based models.
                   Identifying emotion causes at the utterance level in
                   conversations is particularly challenging due to the
                   intermingling dynamics among the interlocutors. Method: We
                   introduce the task of Recognizing Emotion Cause in
                   CONversations with an accompanying dataset named RECCON,
                   containing over 1,000 dialogues and 10,000 utterance
                   cause-effect pairs. Furthermore, we define different cause
                   types based on the source of the causes, and establish
                   strong Transformer-based baselines to address two different
                   sub-tasks on this dataset: causal span extraction and causal
                   emotion entailment. Result: Our Transformer-based baselines,
                   which leverage contextual pre-trained embeddings, such as
                   RoBERTa, outperform the state-of-the-art emotion cause
                   extraction approaches Conclusion: We introduce a new task
                   highly relevant for (explainable) emotion-aware artificial
                   intelligence: recognizing emotion cause in conversations,
                   provide a new highly challenging publicly available
                   dialogue-level dataset for this task, and give strong
                   baseline results on this dataset.",
  month         =  dec,
  year          =  2020,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2012.11820"
}

@ARTICLE{Krizhevsky2012-qe,
  title     = "{ImageNet} classification with deep convolutional neural
               networks",
  author    = "Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E",
  abstract  = "We trained a large, deep convolutional neural network to
               classify the 1.2 million high-resolution images in the ImageNet
               LSVRC-2010 contest into the 1000 different classes. On the test
               data, we achieved top-1 and top-5 error rates of 37.5\% and
               17.0\%, respectively, which is considerably better than the
               previous state-of-the-art. The neural network, which has 60
               million parameters and 650,000 neurons, consists of five
               convolutional layers, some of which are followed by max-pooling
               layers, and three fully connected layers with a final 1000-way
               softmax. To make training faster, we used non-saturating neurons
               and a very efficient GPU implementation of the convolution
               operation. To reduce overfitting in the fully connected layers
               we employed a recently developed regularization method called
               ``dropout'' that proved to be very effective. We also entered a
               variant of this model in the ILSVRC-2012 competition and
               achieved a winning top-5 test error rate of 15.3\%, compared to
               26.2\% achieved by the second-best entry.",
  journal   = "Commun. ACM",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  60,
  number    =  6,
  pages     = "84--90",
  month     =  jan,
  year      =  2012,
  keywords  = "thesis/prior work",
  copyright = "http://www.acm.org/publications/policies/copyright\_policy\#Background",
  language  = "en"
}

@ARTICLE{Qin2020-pn,
  title         = "Back to the Future: Unsupervised Backprop-based Decoding for
                   Counterfactual and Abductive Commonsense Reasoning",
  author        = "Qin, Lianhui and Shwartz, Vered and West, Peter and
                   Bhagavatula, Chandra and Hwang, Jena and Le Bras, Ronan and
                   Bosselut, Antoine and Choi, Yejin",
  abstract      = "Abductive and counterfactual reasoning, core abilities of
                   everyday human cognition, require reasoning about what might
                   have happened at time t, while conditioning on multiple
                   contexts from the relative past and future. However,
                   simultaneous incorporation of past and future contexts using
                   generative language models (LMs) can be challenging, as they
                   are trained either to condition only on the past context or
                   to perform narrowly scoped text-infilling. In this paper, we
                   propose DeLorean, a new unsupervised decoding algorithm that
                   can flexibly incorporate both the past and future contexts
                   using only off-the-shelf, left-to-right language models and
                   no supervision. The key intuition of our algorithm is
                   incorporating the future through back-propagation, during
                   which, we only update the internal representation of the
                   output while fixing the model parameters. By alternating
                   between forward and backward propagation, DeLorean can
                   decode the output representation that reflects both the left
                   and right contexts. We demonstrate that our approach is
                   general and applicable to two nonmonotonic reasoning tasks:
                   abductive text generation and counterfactual story revision,
                   where DeLorean outperforms a range of unsupervised and some
                   supervised methods, based on automatic and human evaluation.",
  month         =  oct,
  year          =  2020,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2010.05906"
}

@ARTICLE{Huang2020-zs,
  title         = "{GRADE}: Automatic {Graph-Enhanced} Coherence Metric for
                   Evaluating {Open-Domain} Dialogue Systems",
  author        = "Huang, Lishan and Ye, Zheng and Qin, Jinghui and Lin, Liang
                   and Liang, Xiaodan",
  abstract      = "Automatically evaluating dialogue coherence is a challenging
                   but high-demand ability for developing high-quality
                   open-domain dialogue systems. However, current evaluation
                   metrics consider only surface features or utterance-level
                   semantics, without explicitly considering the fine-grained
                   topic transition dynamics of dialogue flows. Here, we first
                   consider that the graph structure constituted with topics in
                   a dialogue can accurately depict the underlying
                   communication logic, which is a more natural way to produce
                   persuasive metrics. Capitalized on the topic-level dialogue
                   graph, we propose a new evaluation metric GRADE, which
                   stands for Graph-enhanced Representations for Automatic
                   Dialogue Evaluation. Specifically, GRADE incorporates both
                   coarse-grained utterance-level contextualized
                   representations and fine-grained topic-level graph
                   representations to evaluate dialogue coherence. The graph
                   representations are obtained by reasoning over topic-level
                   dialogue graphs enhanced with the evidence from a
                   commonsense graph, including k-hop neighboring
                   representations and hop-attention weights. Experimental
                   results show that our GRADE significantly outperforms other
                   state-of-the-art metrics on measuring diverse dialogue
                   models in terms of the Pearson and Spearman correlations
                   with human judgements. Besides, we release a new large-scale
                   human evaluation benchmark to facilitate future research on
                   automatic metrics.",
  month         =  oct,
  year          =  2020,
  keywords      = "benchmark;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2010.03994"
}

@ARTICLE{Lin2020-ik,
  title         = "Birds have four legs?! {NumerSense}: Probing Numerical
                   Commonsense Knowledge of Pre-trained Language Models",
  author        = "Lin, Bill Yuchen and Lee, Seyeon and Khanna, Rahul and Ren,
                   Xiang",
  abstract      = "Recent works show that pre-trained language models (PTLMs),
                   such as BERT, possess certain commonsense and factual
                   knowledge. They suggest that it is promising to use PTLMs as
                   ``neural knowledge bases'' via predicting masked words.
                   Surprisingly, we find that this may not work for numerical
                   commonsense knowledge (e.g., a bird usually has two legs).
                   In this paper, we investigate whether and to what extent we
                   can induce numerical commonsense knowledge from PTLMs as
                   well as the robustness of this process. To study this, we
                   introduce a novel probing task with a diagnostic dataset,
                   NumerSense, containing 13.6k masked-word-prediction probes
                   (10.5k for fine-tuning and 3.1k for testing). Our analysis
                   reveals that: (1) BERT and its stronger variant RoBERTa
                   perform poorly on the diagnostic dataset prior to any
                   fine-tuning; (2) fine-tuning with distant supervision brings
                   some improvement; (3) the best supervised model still
                   performs poorly as compared to human performance (54.06\% vs
                   96.3\% in accuracy).",
  month         =  may,
  year          =  2020,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2005.00683"
}

@ARTICLE{Lourie2021-oo,
  title    = "{UNICORN} on {RAINBOW}: A Universal Commonsense Reasoning Model
              on a New Multitask Benchmark",
  author   = "Lourie, Nicholas and Le Bras, Ronan and Bhagavatula, Chandra and
              Choi, Yejin",
  abstract = "Commonsense AI has long been seen as a near impossible
              goal---until recently. Now, research interest has sharply
              increased with an influx of new benchmarks and models. We propose
              two new ways to evaluate commonsense models, emphasizing their
              generality on new tasks and building on diverse, recently
              introduced benchmarks. First, we propose a new multitask
              benchmark, Rainbow, to promote research on commonsense models
              that generalize well over multiple tasks and datasets. Second, we
              propose a novel evaluation, the cost equivalent curve, that sheds
              new insight on how the choice of source datasets, pretrained
              language models, and transfer learning methods impacts
              performance and data efficiency. We perform extensive
              experiments---over 200 experiments encompassing 4800 models---and
              report multiple valuable and sometimes surprising findings, e.g.,
              that transfer almost always leads to better or equivalent
              performance if following a particular recipe, that QA-based
              commonsense datasets transfer well with each other, while
              commonsense knowledge graphs do not, and that perhaps
              counter-intuitively, larger models benefit more from transfer
              than smaller ones. Last but not least, we introduce a new
              universal commonsense reasoning model, UNICORN, that establishes
              new state-of-the-art performance across 8 popular commonsense
              benchmarks, aNLI (87.3\%), CosmosQA (91.8\%), HellaSWAG (93.9\%),
              PIQA (90.1\%), SocialIQa (83.2\%), WinoGrande (86.6\%), CycIC
              (94.0\%) and CommonsenseQA (79.3\%).",
  journal  = "AAAI",
  volume   =  35,
  number   =  15,
  pages    = "13480--13488",
  month    =  may,
  year     =  2021,
  keywords = "Language Models; Question Answering;commonsense
              reasoning;thesis/prior work",
  language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bisk2020-hw,
  title    = "{PIQA}: Reasoning about Physical Commonsense in Natural Language",
  author   = "Bisk, Yonatan and Zellers, Rowan and Le bras, Ronan and Gao,
              Jianfeng and Choi, Yejin",
  abstract = "To apply eyeshadow without a brush, should I use a cotton swab or
              a toothpick? Questions requiring this kind of physical
              commonsense pose a challenge to today's natural language
              understanding systems. While recent pretrained models (such as
              BERT) have made progress on question answering over more abstract
              domains -- such as news articles and encyclopedia entries, where
              text is plentiful -- in more physical domains, text is inherently
              limited due to reporting bias. Can AI systems learn to reliably
              answer physical commonsense questions without experiencing the
              physical world?In this paper, we introduce the task of physical
              commonsense reasoning and a corresponding benchmark dataset
              Physical Interaction: Question Answering or PIQA. Though humans
              find the dataset easy (95\% accuracy), large pretrained models
              struggle (75\%). We provide analysis about the dimensions of
              knowledge that existing models lack, which offers significant
              opportunities for future research.",
  journal  = "AAAI",
  volume   =  34,
  number   =  05,
  pages    = "7432--7439",
  month    =  apr,
  year     =  2020,
  keywords = "commonsense reasoning;thesis/prior work",
  language = "en"
}

@ARTICLE{Zellers2018-hu,
  title         = "{SWAG}: A {Large-Scale} Adversarial Dataset for Grounded
                   Commonsense Inference",
  author        = "Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi,
                   Yejin",
  abstract      = "Given a partial description like ``she opened the hood of
                   the car,'' humans can reason about the situation and
                   anticipate what might come next (``then, she examined the
                   engine''). In this paper, we introduce the task of grounded
                   commonsense inference, unifying natural language inference
                   and commonsense reasoning. We present SWAG, a new dataset
                   with 113k multiple choice questions about a rich spectrum of
                   grounded situations. To address the recurring challenges of
                   the annotation artifacts and human biases found in many
                   existing datasets, we propose Adversarial Filtering (AF), a
                   novel procedure that constructs a de-biased dataset by
                   iteratively training an ensemble of stylistic classifiers,
                   and using them to filter the data. To account for the
                   aggressive adversarial filtering, we use state-of-the-art
                   language models to massively oversample a diverse set of
                   potential counterfactuals. Empirical results demonstrate
                   that while humans can solve the resulting inference problems
                   with high accuracy (88\%), various competitive models
                   struggle on our task. We provide comprehensive analysis that
                   indicates significant opportunities for future research.",
  month         =  aug,
  year          =  2018,
  keywords      = "commonsense reasoning;dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1808.05326"
}

@ARTICLE{Bhagavatula2019-mn,
  title         = "Abductive Commonsense Reasoning",
  author        = "Bhagavatula, Chandra and Le Bras, Ronan and Malaviya,
                   Chaitanya and Sakaguchi, Keisuke and Holtzman, Ari and
                   Rashkin, Hannah and Downey, Doug and Yih, Scott Wen-Tau and
                   Choi, Yejin",
  abstract      = "Abductive reasoning is inference to the most plausible
                   explanation. For example, if Jenny finds her house in a mess
                   when she returns from work, and remembers that she left a
                   window open, she can hypothesize that a thief broke into her
                   house and caused the mess, as the most plausible
                   explanation. While abduction has long been considered to be
                   at the core of how people interpret and read between the
                   lines in natural language (Hobbs et al., 1988), there has
                   been relatively little research in support of abductive
                   natural language inference and generation. We present the
                   first study that investigates the viability of
                   language-based abductive reasoning. We introduce a challenge
                   dataset, ART, that consists of over 20k commonsense
                   narrative contexts and 200k explanations. Based on this
                   dataset, we conceptualize two new tasks -- (i) Abductive
                   NLI: a multiple-choice question answering task for choosing
                   the more likely explanation, and (ii) Abductive NLG: a
                   conditional generation task for explaining given
                   observations in natural language. On Abductive NLI, the best
                   model achieves 68.9\% accuracy, well below human performance
                   of 91.4\%. On Abductive NLG, the current best language
                   generators struggle even more, as they lack reasoning
                   capabilities that are trivial for humans. Our analysis leads
                   to new insights into the types of reasoning that deep
                   pre-trained language models fail to perform--despite their
                   strong performance on the related but more narrowly defined
                   task of entailment NLI--pointing to interesting avenues for
                   future research.",
  month         =  aug,
  year          =  2019,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1908.05739"
}

@ARTICLE{Huang2019-nw,
  title         = "Cosmos {QA}: Machine Reading Comprehension with Contextual
                   Commonsense Reasoning",
  author        = "Huang, Lifu and Le Bras, Ronan and Bhagavatula, Chandra and
                   Choi, Yejin",
  abstract      = "Understanding narratives requires reading between the lines,
                   which in turn, requires interpreting the likely causes and
                   effects of events, even when they are not mentioned
                   explicitly. In this paper, we introduce Cosmos QA, a
                   large-scale dataset of 35,600 problems that require
                   commonsense-based reading comprehension, formulated as
                   multiple-choice questions. In stark contrast to most
                   existing reading comprehension datasets where the questions
                   focus on factual and literal understanding of the context
                   paragraph, our dataset focuses on reading between the lines
                   over a diverse collection of people's everyday narratives,
                   asking such questions as ``what might be the possible reason
                   of ...?'', or ``what would have happened if ...'' that
                   require reasoning beyond the exact text spans in the
                   context. To establish baseline performances on Cosmos QA, we
                   experiment with several state-of-the-art neural
                   architectures for reading comprehension, and also propose a
                   new architecture that improves over the competitive
                   baselines. Experimental results demonstrate a significant
                   gap between machine (68.4\%) and human performance (94\%),
                   pointing to avenues for future research on commonsense
                   machine comprehension. Dataset, code and leaderboard is
                   publicly available at https://wilburone.github.io/cosmos.",
  month         =  aug,
  year          =  2019,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1909.00277"
}

@ARTICLE{Sakaguchi2021-cy,
  title     = "{WinoGrande}: an adversarial winograd schema challenge at scale",
  author    = "Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra
               and Choi, Yejin",
  abstract  = "Commonsense reasoning remains a major challenge in AI, and yet,
               recent progresses on benchmarks may seem to suggest otherwise.
               In particular, the recent neural language models have reported
               above 90\% accuracy on the Winograd Schema Challenge (WSC), a
               commonsense benchmark originally designed to be unsolvable for
               statistical models that rely simply on word associations. This
               raises an important question---whether these models have truly
               acquired robust commonsense capabilities or they rely on
               spurious biases in the dataset that lead to an overestimation of
               the true capabilities of machine commonsense.To investigate this
               question, we introduce WinoGrande, a large-scale dataset of 44k
               problems, inspired by the original WSC, but adjusted to improve
               both the scale and the hardness of the dataset. The key steps of
               the dataset construction consist of (1) large-scale
               crowdsourcing, followed by (2) systematic bias reduction using a
               novel AFLITE algorithm that generalizes human-detectable word
               associations to machine-detectable embedding associations. Our
               experiments demonstrate that state-of-the-art models achieve
               considerably lower accuracy (59.4\%-79.1\%) on WINOGRANDE
               compared to humans (94\%), confirming that the high performance
               on the original WSC was inflated by spurious biases in the
               dataset.Furthermore, we report new state-of-the-art results on
               five related benchmarks with emphasis on their dual
               implications. On the one hand, they demonstrate the
               effectiveness of WINOGRANDE when used as a resource for transfer
               learning. On the other hand, the high performance on all these
               benchmarks suggests the extent to which spurious biases are
               prevalent in all such datasets, which motivates further research
               on algorithmic bias reduction.",
  journal   = "Commun. ACM",
  publisher = "Association for Computing Machinery",
  volume    =  64,
  number    =  9,
  pages     = "99--106",
  month     =  aug,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "thesis/prior work"
}

@ARTICLE{Khot2020-dh,
  title    = "{QASC}: A Dataset for Question Answering via Sentence Composition",
  author   = "Khot, Tushar and Clark, Peter and Guerquin, Michal and Jansen,
              Peter and Sabharwal, Ashish",
  abstract = "Composing knowledge from multiple pieces of texts is a key
              challenge in multi-hop question answering. We present a multi-hop
              reasoning dataset, Question Answering via Sentence Composition
              (QASC), that requires retrieving facts from a large corpus and
              composing them to answer a multiple-choice question. QASC is the
              first dataset to offer two desirable properties: (a) the facts to
              be composed are annotated in a large corpus, and (b) the
              decomposition into these facts is not evident from the question
              itself. The latter makes retrieval challenging as the system must
              introduce new concepts or relations in order to discover
              potential decompositions. Further, the reasoning model must then
              learn to identify valid compositions of these retrieved facts
              using common-sense reasoning. To help address these challenges,
              we provide annotation for supporting facts as well as their
              composition. Guided by these annotations, we present a two-step
              approach to mitigate the retrieval challenges. We use other
              multiple-choice datasets as additional training data to
              strengthen the reasoning model. Our proposed approach improves
              over current state-of-the-art language models by 11\% (absolute).
              The reasoning and retrieval problems, however, remain unsolved as
              this model still lags by 20\% behind human performance.",
  journal  = "AAAI",
  volume   =  34,
  number   =  05,
  pages    = "8082--8090",
  month    =  apr,
  year     =  2020,
  keywords = "commonsense reasoning;dataset;thesis/prior work",
  language = "en"
}

@ARTICLE{Hendrycks2020-ed,
  title         = "Aligning {AI} With Shared Human Values",
  author        = "Hendrycks, Dan and Burns, Collin and Basart, Steven and
                   Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt,
                   Jacob",
  abstract      = "We show how to assess a language model's knowledge of basic
                   concepts of morality. We introduce the ETHICS dataset, a new
                   benchmark that spans concepts in justice, well-being,
                   duties, virtues, and commonsense morality. Models predict
                   widespread moral judgments about diverse text scenarios.
                   This requires connecting physical and social world knowledge
                   to value judgements, a capability that may enable us to
                   steer chatbot outputs or eventually regularize open-ended
                   reinforcement learning agents. With the ETHICS dataset, we
                   find that current language models have a promising but
                   incomplete ability to predict basic human ethical
                   judgements. Our work shows that progress can be made on
                   machine ethics today, and it provides a steppingstone toward
                   AI that is aligned with human values.",
  month         =  aug,
  year          =  2020,
  keywords      = "commonsense reasoning;dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CY",
  eprint        = "2008.02275"
}

@ARTICLE{Singh2021-ui,
  title         = "{COM2SENSE}: A Commonsense Reasoning Benchmark with
                   Complementary Sentences",
  author        = "Singh, Shikhar and Wen, Nuan and Hou, Yu and
                   Alipoormolabashi, Pegah and Wu, Te-Lin and Ma, Xuezhe and
                   Peng, Nanyun",
  abstract      = "Commonsense reasoning is intuitive for humans but has been a
                   long-term challenge for artificial intelligence (AI). Recent
                   advancements in pretrained language models have shown
                   promising results on several commonsense benchmark datasets.
                   However, the reliability and comprehensiveness of these
                   benchmarks towards assessing model's commonsense reasoning
                   ability remains unclear. To this end, we introduce a new
                   commonsense reasoning benchmark dataset comprising natural
                   language true/false statements, with each sample paired with
                   its complementary counterpart, resulting in 4k sentence
                   pairs. We propose a pairwise accuracy metric to reliably
                   measure an agent's ability to perform commonsense reasoning
                   over a given situation. The dataset is crowdsourced and
                   enhanced with an adversarial model-in-the-loop setup to
                   incentivize challenging samples. To facilitate a systematic
                   analysis of commonsense capabilities, we design our dataset
                   along the dimensions of knowledge domains, reasoning
                   scenarios and numeracy. Experimental results demonstrate
                   that our strongest baseline (UnifiedQA-3B), after
                   fine-tuning, achieves ~71\% standard accuracy and ~51\%
                   pairwise accuracy, well below human performance (~95\% for
                   both metrics). The dataset is available at
                   https://github.com/PlusLabNLP/Com2Sense.",
  month         =  jun,
  year          =  2021,
  keywords      = "benchmark;commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2106.00969"
}

@ARTICLE{Talmor2022-gl,
  title         = "{CommonsenseQA} 2.0: Exposing the Limits of {AI} through
                   Gamification",
  author        = "Talmor, Alon and Yoran, Ori and Le Bras, Ronan and
                   Bhagavatula, Chandra and Goldberg, Yoav and Choi, Yejin and
                   Berant, Jonathan",
  abstract      = "Constructing benchmarks that test the abilities of modern
                   natural language understanding models is difficult -
                   pre-trained language models exploit artifacts in benchmarks
                   to achieve human parity, but still fail on adversarial
                   examples and make errors that demonstrate a lack of common
                   sense. In this work, we propose gamification as a framework
                   for data construction. The goal of players in the game is to
                   compose questions that mislead a rival AI while using
                   specific phrases for extra points. The game environment
                   leads to enhanced user engagement and simultaneously gives
                   the game designer control over the collected data, allowing
                   us to collect high-quality data at scale. Using our method
                   we create CommonsenseQA 2.0, which includes 14,343 yes/no
                   questions, and demonstrate its difficulty for models that
                   are orders-of-magnitude larger than the AI used in the game
                   itself. Our best baseline, the T5-based Unicorn with 11B
                   parameters achieves an accuracy of 70.2\%, substantially
                   higher than GPT-3 (52.9\%) in a few-shot inference setup.
                   Both score well below human performance which is at 94.1\%.",
  month         =  jan,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2201.05320"
}

@ARTICLE{Choi2022-to,
  title     = "The Curious Case of Commonsense Intelligence",
  author    = "Choi, Yejin",
  abstract  = "Commonsense intelligence is a long-standing puzzle in AI.
               Despite considerable advances in deep learning, AI continues to
               be narrow and brittle due to its lack of common sense. Why is
               common sense so trivial for humans but so hard for machines? In
               this essay, I map the twists and turns in recent research
               adventures toward commonsense AI. As we will see, the latest
               advances on common sense are riddled with new, potentially
               counterintuitive perspectives and questions. In particular, I
               discuss the significance of language for modeling intuitive
               reasoning, the fundamental limitations of logic formalisms
               despite their intellectual appeal, the case for on-the-fly
               generative reasoning through language, the continuum between
               knowledge and reasoning, and the blend between symbolic and
               neural knowledge representations.",
  journal   = "Daedalus",
  publisher = "MIT Press",
  volume    =  151,
  number    =  2,
  pages     = "139--155",
  month     =  may,
  year      =  2022,
  keywords  = "commonsense reasoning;thesis/prior work"
}

@ARTICLE{Yi2022-tv,
  title         = "Contextual Information and Commonsense Based Prompt for
                   Emotion Recognition in Conversation",
  author        = "Yi, Jingjie and Yang, Deqing and Yuan, Siyu and Cao, Caiyan
                   and Zhang, Zhiyao and Xiao, Yanghua",
  abstract      = "Emotion recognition in conversation (ERC) aims to detect the
                   emotion for each utterance in a given conversation. The
                   newly proposed ERC models have leveraged pre-trained
                   language models (PLMs) with the paradigm of pre-training and
                   fine-tuning to obtain good performance. However, these
                   models seldom exploit PLMs' advantages thoroughly, and
                   perform poorly for the conversations lacking explicit
                   emotional expressions. In order to fully leverage the latent
                   knowledge related to the emotional expressions in
                   utterances, we propose a novel ERC model CISPER with the new
                   paradigm of prompt and language model (LM) tuning.
                   Specifically, CISPER is equipped with the prompt blending
                   the contextual information and commonsense related to the
                   interlocutor's utterances, to achieve ERC more effectively.
                   Our extensive experiments demonstrate CISPER's superior
                   performance over the state-of-the-art ERC models, and the
                   effectiveness of leveraging these two kinds of significant
                   prompt information for performance gains. To reproduce our
                   experimental results conveniently, CISPER's sourcecode and
                   the datasets have been shared at
                   https://github.com/DeqingYang/CISPER.",
  month         =  jul,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2207.13254"
}

@ARTICLE{Zhang2021-kb,
  title         = "Multi-turn Dialogue Reading Comprehension with Pivot Turns
                   and Knowledge",
  author        = "Zhang, Zhuosheng and Li, Junlong and Zhao, Hai",
  abstract      = "Multi-turn dialogue reading comprehension aims to teach
                   machines to read dialogue contexts and solve tasks such as
                   response selection and answering questions. The major
                   challenges involve noisy history contexts and especial
                   prerequisites of commonsense knowledge that is unseen in the
                   given material. Existing works mainly focus on context and
                   response matching approaches. This work thus makes the first
                   attempt to tackle the above two challenges by extracting
                   substantially important turns as pivot utterances and
                   utilizing external knowledge to enhance the representation
                   of context. We propose a pivot-oriented deep selection model
                   (PoDS) on top of the Transformer-based language models for
                   dialogue comprehension. In detail, our model first picks out
                   the pivot utterances from the conversation history according
                   to the semantic matching with the candidate response or
                   question, if any. Besides, knowledge items related to the
                   dialogue context are extracted from a knowledge graph as
                   external knowledge. Then, the pivot utterances and the
                   external knowledge are combined with a well-designed
                   mechanism for refining predictions. Experimental results on
                   four dialogue comprehension benchmark tasks show that our
                   proposed model achieves great improvements on baselines. A
                   series of empirical comparisons are conducted to show how
                   our selection strategies and the extra knowledge injection
                   influence the results.",
  month         =  feb,
  year          =  2021,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2102.05474"
}

@ARTICLE{Arabshahi2021-oz,
  title    = "Conversational {Neuro-Symbolic} Commonsense Reasoning",
  author   = "Arabshahi, Forough and Lee, Jennifer and Gawarecki, Mikayla and
              Mazaitis, Kathryn and Azaria, Amos and Mitchell, Tom",
  journal  = "AAAI",
  volume   =  35,
  number   =  6,
  pages    = "4902--4911",
  month    =  may,
  year     =  2021,
  keywords = "need to include in proposal outline;commonsense
              reasoning;dataset;thesis/prior work",
  language = "en"
}

@ARTICLE{Kim2022-ji,
  title         = "{ProsocialDialog}: A Prosocial Backbone for Conversational
                   Agents",
  author        = "Kim, Hyunwoo and Yu, Youngjae and Jiang, Liwei and Lu,
                   Ximing and Khashabi, Daniel and Kim, Gunhee and Choi, Yejin
                   and Sap, Maarten",
  abstract      = "Most existing dialogue systems fail to respond properly to
                   potentially unsafe user utterances by either ignoring or
                   passively agreeing with them. To address this issue, we
                   introduce ProsocialDialog, the first large-scale multi-turn
                   dialogue dataset to teach conversational agents to respond
                   to problematic content following social norms. Covering
                   diverse unethical, problematic, biased, and toxic
                   situations, ProsocialDialog contains responses that
                   encourage prosocial behavior, grounded in commonsense social
                   rules (i.e., rules-of-thumb, RoTs). Created via a human-AI
                   collaborative framework, ProsocialDialog consists of 58K
                   dialogues, with 331K utterances, 160K unique RoTs, and 497K
                   dialogue safety labels accompanied by free-form rationales.
                   With this dataset, we introduce a dialogue safety detection
                   module, Canary, capable of generating RoTs given
                   conversational context, and a socially-informed dialogue
                   agent, Prost. Empirical results show that Prost generates
                   more socially acceptable dialogues compared to other
                   state-of-the-art language and dialogue models in both
                   in-domain and out-of-domain settings. Additionally, Canary
                   effectively guides conversational agents and off-the-shelf
                   language models to generate significantly more prosocial
                   responses. Our work highlights the promise and importance of
                   creating and steering conversational AI to be socially
                   responsible.",
  month         =  may,
  year          =  2022,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2205.12688"
}

@ARTICLE{Forbes2020-to,
  title         = "Social Chemistry 101: Learning to Reason about Social and
                   Moral Norms",
  author        = "Forbes, Maxwell and Hwang, Jena D and Shwartz, Vered and
                   Sap, Maarten and Choi, Yejin",
  abstract      = "Social norms -- the unspoken commonsense rules about
                   acceptable social behavior -- are crucial in understanding
                   the underlying causes and intents of people's actions in
                   narratives. For example, underlying an action such as
                   ``wanting to call cops on my neighbors'' are social norms
                   that inform our conduct, such as ``It is expected that you
                   report crimes.'' We present Social Chemistry, a new
                   conceptual formalism to study people's everyday social norms
                   and moral judgments over a rich spectrum of real life
                   situations described in natural language. We introduce
                   Social-Chem-101, a large-scale corpus that catalogs 292k
                   rules-of-thumb such as ``it is rude to run a blender at
                   5am'' as the basic conceptual units. Each rule-of-thumb is
                   further broken down with 12 different dimensions of people's
                   judgments, including social judgments of good and bad, moral
                   foundations, expected cultural pressure, and assumed
                   legality, which together amount to over 4.5 million
                   annotations of categorical labels and free-text
                   descriptions. Comprehensive empirical results based on
                   state-of-the-art neural models demonstrate that
                   computational modeling of social norms is a promising
                   research direction. Our model framework, Neural Norm
                   Transformer, learns and generalizes Social-Chem-101 to
                   successfully reason about previously unseen situations,
                   generating relevant (and potentially novel) attribute-aware
                   social rules-of-thumb.",
  month         =  nov,
  year          =  2020,
  keywords      = "need to include in proposal outline;dataset;thesis/prior
                   work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2011.00620"
}

@ARTICLE{Ziems2022-vb,
  title         = "The Moral Integrity Corpus: A Benchmark for Ethical Dialogue
                   Systems",
  author        = "Ziems, Caleb and Yu, Jane A and Wang, Yi-Chia and Halevy,
                   Alon and Yang, Diyi",
  abstract      = "Conversational agents have come increasingly closer to human
                   competence in open-domain dialogue settings; however, such
                   models can reflect insensitive, hurtful, or entirely
                   incoherent viewpoints that erode a user's trust in the moral
                   integrity of the system. Moral deviations are difficult to
                   mitigate because moral judgments are not universal, and
                   there may be multiple competing judgments that apply to a
                   situation simultaneously. In this work, we introduce a new
                   resource, not to authoritatively resolve moral ambiguities,
                   but instead to facilitate systematic understanding of the
                   intuitions, values and moral judgments reflected in the
                   utterances of dialogue systems. The Moral Integrity Corpus,
                   MIC, is such a resource, which captures the moral
                   assumptions of 38k prompt-reply pairs, using 99k distinct
                   Rules of Thumb (RoTs). Each RoT reflects a particular moral
                   conviction that can explain why a chatbot's reply may appear
                   acceptable or problematic. We further organize RoTs with a
                   set of 9 moral and social attributes and benchmark
                   performance for attribute classification. Most importantly,
                   we show that current neural language models can
                   automatically generate new RoTs that reasonably describe
                   previously unseen interactions, but they still struggle with
                   certain scenarios. Our findings suggest that MIC will be a
                   useful resource for understanding and language models'
                   implicit moral assumptions and flexibly benchmarking the
                   integrity of conversational agents. To download the data,
                   see https://github.com/GT-SALT/mic",
  month         =  apr,
  year          =  2022,
  keywords      = "benchmark;dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2204.03021"
}

@ARTICLE{Miller2017-fj,
  title         = "{ParlAI}: A Dialog Research Software Platform",
  author        = "Miller, Alexander H and Feng, Will and Fisch, Adam and Lu,
                   Jiasen and Batra, Dhruv and Bordes, Antoine and Parikh, Devi
                   and Weston, Jason",
  abstract      = "We introduce ParlAI (pronounced ``par-lay''), an open-source
                   software platform for dialog research implemented in Python,
                   available at http://parl.ai. Its goal is to provide a
                   unified framework for sharing, training and testing of
                   dialog models, integration of Amazon Mechanical Turk for
                   data collection, human evaluation, and online/reinforcement
                   learning; and a repository of machine learning models for
                   comparing with others' models, and improving upon existing
                   architectures. Over 20 tasks are supported in the first
                   release, including popular datasets such as SQuAD, bAbI
                   tasks, MCTest, WikiQA, QACNN, QADailyMail, CBT, bAbI Dialog,
                   Ubuntu, OpenSubtitles and VQA. Several models are
                   integrated, including neural models such as memory networks,
                   seq2seq and attentive LSTMs.",
  month         =  may,
  year          =  2017,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1705.06476"
}

@ARTICLE{Zhou2021-yq,
  title         = "Probing Commonsense Explanation in Dialogue Response
                   Generation",
  author        = "Zhou, Pei and Jandaghi, Pegah and Lin, Bill Yuchen and Cho,
                   Justin and Pujara, Jay and Ren, Xiang",
  abstract      = "Humans use commonsense reasoning (CSR) implicitly to produce
                   natural and coherent responses in conversations. Aiming to
                   close the gap between current response generation (RG)
                   models and human communication abilities, we want to
                   understand why RG models respond as they do by probing RG
                   model's understanding of commonsense reasoning that elicits
                   proper responses. We formalize the problem by framing
                   commonsense as a latent variable in the RG task and using
                   explanations for responses as textual form of commonsense.
                   We collect 6k annotated explanations justifying responses
                   from four dialogue datasets and ask humans to verify them
                   and propose two probing settings to evaluate RG models' CSR
                   capabilities. Probing results show that models fail to
                   capture the logical relations between commonsense
                   explanations and responses and fine-tuning on in-domain data
                   and increasing model sizes do not lead to understanding of
                   CSR for RG. We hope our study motivates more research in
                   making RG models emulate the human reasoning process in
                   pursuit of smooth human-AI communication.",
  month         =  apr,
  year          =  2021,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2104.09574"
}

@ARTICLE{Sap2019-hu,
  title         = "{SocialIQA}: Commonsense Reasoning about Social Interactions",
  author        = "Sap, Maarten and Rashkin, Hannah and Chen, Derek and LeBras,
                   Ronan and Choi, Yejin",
  abstract      = "We introduce Social IQa, the first largescale benchmark for
                   commonsense reasoning about social situations. Social IQa
                   contains 38,000 multiple choice questions for probing
                   emotional and social intelligence in a variety of everyday
                   situations (e.g., Q: ``Jordan wanted to tell Tracy a secret,
                   so Jordan leaned towards Tracy. Why did Jordan do this?'' A:
                   ``Make sure no one else could hear''). Through
                   crowdsourcing, we collect commonsense questions along with
                   correct and incorrect answers about social interactions,
                   using a new framework that mitigates stylistic artifacts in
                   incorrect answers by asking workers to provide the right
                   answer to a different but related question. Empirical
                   results show that our benchmark is challenging for existing
                   question-answering models based on pretrained language
                   models, compared to human performance (>20\% gap). Notably,
                   we further establish Social IQa as a resource for transfer
                   learning of commonsense knowledge, achieving
                   state-of-the-art performance on multiple commonsense
                   reasoning tasks (Winograd Schemas, COPA).",
  month         =  apr,
  year          =  2019,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1904.09728"
}

@ARTICLE{Qin2021-jy,
  title         = "{TIMEDIAL}: Temporal Commonsense Reasoning in Dialog",
  author        = "Qin, Lianhui and Gupta, Aditya and Upadhyay, Shyam and He,
                   Luheng and Choi, Yejin and Faruqui, Manaal",
  abstract      = "Everyday conversations require understanding everyday
                   events, which in turn, requires understanding temporal
                   commonsense concepts interwoven with those events. Despite
                   recent progress with massive pre-trained language models
                   (LMs) such as T5 and GPT-3, their capability of temporal
                   reasoning in dialogs remains largely under-explored. In this
                   paper, we present the first study to investigate pre-trained
                   LMs for their temporal reasoning capabilities in dialogs by
                   introducing a new task and a crowd-sourced English challenge
                   set, TIMEDIAL. We formulate TIME-DIAL as a multiple-choice
                   cloze task with over 1.1K carefully curated dialogs.
                   Empirical results demonstrate that even the best performing
                   models struggle on this task compared to humans, with 23
                   absolute points of gap in accuracy. Furthermore, our
                   analysis reveals that the models fail to reason about dialog
                   context correctly; instead, they rely on shallow cues based
                   on existing temporal patterns in context, motivating future
                   research for modeling temporal concepts in text and robust
                   contextual reasoning about them. The dataset is publicly
                   available at:
                   https://github.com/google-research-datasets/timedial.",
  month         =  jun,
  year          =  2021,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2106.04571"
}

@ARTICLE{Ghosal2022-si,
  title         = "{CICERO}: A Dataset for Contextualized Commonsense Inference
                   in Dialogues",
  author        = "Ghosal, Deepanway and Shen, Siqi and Majumder, Navonil and
                   Mihalcea, Rada and Poria, Soujanya",
  abstract      = "This paper addresses the problem of dialogue reasoning with
                   contextualized commonsense inference. We curate CICERO, a
                   dataset of dyadic conversations with five types of
                   utterance-level reasoning-based inferences: cause,
                   subsequent event, prerequisite, motivation, and emotional
                   reaction. The dataset contains 53,105 of such inferences
                   from 5,672 dialogues. We use this dataset to solve relevant
                   generative and discriminative tasks: generation of cause and
                   subsequent event; generation of prerequisite, motivation,
                   and listener's emotional reaction; and selection of
                   plausible alternatives. Our results ascertain the value of
                   such dialogue-centric commonsense knowledge datasets. It is
                   our hope that CICERO will open new research avenues into
                   commonsense-based dialogue reasoning.",
  month         =  mar,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2203.13926"
}

@ARTICLE{Gliwa2019-vb,
  title         = "{SAMSum} Corpus: A Human-annotated Dialogue Dataset for
                   Abstractive Summarization",
  author        = "Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and
                   Wawer, Aleksander",
  abstract      = "This paper introduces the SAMSum Corpus, a new dataset with
                   abstractive dialogue summaries. We investigate the
                   challenges it poses for automated summarization by testing
                   several models and comparing their results with those
                   obtained on a corpus of news articles. We show that
                   model-generated summaries of dialogues achieve higher ROUGE
                   scores than the model-generated summaries of news -- in
                   contrast with human evaluators' judgement. This suggests
                   that a challenging task of abstractive dialogue
                   summarization requires dedicated models and non-standard
                   quality measures. To our knowledge, our study is the first
                   attempt to introduce a high-quality chat-dialogues corpus,
                   manually annotated with abstractive summarizations, which
                   can be used by the research community for further studies.",
  month         =  nov,
  year          =  2019,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1911.12237"
}

@INCOLLECTION{Carletta2006-gj,
  title     = "The {AMI} Meeting Corpus: A Pre-announcement",
  booktitle = "Machine Learning for Multimodal Interaction",
  author    = "Carletta, Jean and Ashby, Simone and Bourban, Sebastien and
               Flynn, Mike and Guillemot, Mael and Hain, Thomas and Kadlec,
               Jaroslav and Karaiskos, Vasilis and Kraaij, Wessel and
               Kronenthal, Melissa and Lathoud, Guillaume and Lincoln, Mike and
               Lisowska, Agnes and McCowan, Iain and Post, Wilfried and
               Reidsma, Dennis and Wellner, Pierre",
  publisher = "Springer Berlin Heidelberg",
  pages     = "28--39",
  series    = "Lecture notes in computer science",
  year      =  2006,
  address   = "Berlin, Heidelberg",
  keywords  = "dataset;need to include in proposal outline;thesis/prior work"
}

@INPROCEEDINGS{Janin2003-ji,
  title     = "The {ICSI} Meeting Corpus",
  booktitle = "2003 {IEEE} International Conference on Acoustics, Speech, and
               Signal Processing, 2003. Proceedings. ({ICASSP} '03).",
  author    = "Janin, A and Baron, D and Edwards, J and Ellis, D and Gelbart, D
               and Morgan, N and Peskin, B and Pfau, T and Shriberg, E and
               Stolcke, A and Wooters, C",
  abstract  = "We have collected a corpus of data from natural meetings that
               occurred at the International Computer Science Institute (ICSI)
               in Berkeley, California over the last three years. The corpus
               contains audio recorded simultaneously from head-worn and
               table-top microphones, word-level transcripts of meetings, and
               various metadata on participants, meetings, and hardware. Such a
               corpus supports work in automatic speech recognition, noise
               robustness, dialog modeling, prosody, rich transcription,
               information retrieval, and more. We present details on the
               contents of the corpus, as well as rationales for the decisions
               that led to its configuration. The corpus were delivered to the
               Linguistic Data Consortium (LDC).",
  volume    =  1,
  pages     = "I--I",
  month     =  apr,
  year      =  2003,
  keywords  = "Speech recognition;Speech processing;Audio
               recording;Microphones;dataset;need to include in proposal
               outline;thesis/prior work"
}

@ARTICLE{Tur2010-jh,
  title    = "The {CALO} Meeting Assistant System",
  author   = "Tur, Gokhan and Stolcke, Andreas and Voss, Lynn and Peters,
              Stanley and Hakkani-Tur, Dilek and Dowding, John and Favre,
              Benoit and Fernandez, Raquel and Frampton, Matthew and Frandsen,
              Mike and Frederickson, Clint and Graciarena, Martin and Kintzing,
              Donald and Leveque, Kyle and Mason, Shane and Niekrasz, John and
              Purver, Matthew and Riedhammer, Korbinian and Shriberg, Elizabeth
              and Tien, Jing and Vergyri, Dimitra and Yang, Fan",
  abstract = "The CALO Meeting Assistant (MA) provides for distributed meeting
              capture, annotation, automatic transcription and semantic
              analysis of multiparty meetings, and is part of the larger CALO
              personal assistant system. This paper presents the CALO-MA
              architecture and its speech recognition and understanding
              components, which include real-time and offline speech
              transcription, dialog act segmentation and tagging, topic
              identification and segmentation, question-answer pair
              identification, action item recognition, decision extraction, and
              summarization.",
  journal  = "IEEE Trans. Audio Speech Lang. Processing",
  volume   =  18,
  number   =  6,
  pages    = "1601--1611",
  month    =  aug,
  year     =  2010,
  keywords = "Speech recognition;Automatic speech recognition;Data
              mining;Natural languages;Data privacy;Speech processing;Ambient
              intelligence;Microphone arrays;Tagging;Productivity;Multiparty
              meetings processing;speech recognition;spoken language
              understanding;need to include in proposal outline;thesis/prior
              work"
}

@ARTICLE{Ni2023-jk,
  title     = "Recent advances in deep learning based dialogue systems: a
               systematic survey",
  author    = "Ni, Jinjie and Young, Tom and Pandelea, Vlad and Xue, Fuzhao and
               Cambria, Erik",
  journal   = "Artif. Intell. Rev.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  56,
  number    =  4,
  pages     = "3055--3155",
  month     =  apr,
  year      =  2023,
  keywords  = "thesis/prior work",
  copyright = "https://www.springernature.com/gp/researchers/text-and-data-mining",
  language  = "en"
}

@ARTICLE{Lowe2015-vo,
  title         = "The Ubuntu Dialogue Corpus: A Large Dataset for Research in
                   Unstructured {Multi-Turn} Dialogue Systems",
  author        = "Lowe, Ryan and Pow, Nissan and Serban, Iulian and Pineau,
                   Joelle",
  abstract      = "This paper introduces the Ubuntu Dialogue Corpus, a dataset
                   containing almost 1 million multi-turn dialogues, with a
                   total of over 7 million utterances and 100 million words.
                   This provides a unique resource for research into building
                   dialogue managers based on neural language models that can
                   make use of large amounts of unlabeled data. The dataset has
                   both the multi-turn property of conversations in the Dialog
                   State Tracking Challenge datasets, and the unstructured
                   nature of interactions from microblog services such as
                   Twitter. We also describe two neural learning architectures
                   suitable for analyzing this dataset, and provide benchmark
                   performance on the task of selecting the best next response.",
  month         =  jun,
  year          =  2015,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1506.08909"
}

@ARTICLE{Sun2019-aq,
  title         = "{DREAM}: A Challenge Dataset and Models for {Dialogue-Based}
                   Reading Comprehension",
  author        = "Sun, Kai and Yu, Dian and Chen, Jianshu and Yu, Dong and
                   Choi, Yejin and Cardie, Claire",
  abstract      = "We present DREAM, the first dialogue-based multiple-choice
                   reading comprehension dataset. Collected from
                   English-as-a-foreign-language examinations designed by human
                   experts to evaluate the comprehension level of Chinese
                   learners of English, our dataset contains 10,197
                   multiple-choice questions for 6,444 dialogues. In contrast
                   to existing reading comprehension datasets, DREAM is the
                   first to focus on in-depth multi-turn multi-party dialogue
                   understanding. DREAM is likely to present significant
                   challenges for existing reading comprehension systems: 84\%
                   of answers are non-extractive, 85\% of questions require
                   reasoning beyond a single sentence, and 34\% of questions
                   also involve commonsense knowledge. We apply several popular
                   neural reading comprehension models that primarily exploit
                   surface information within the text and find them to, at
                   best, just barely outperform a rule-based approach. We next
                   investigate the effects of incorporating dialogue structure
                   and different kinds of general world knowledge into both
                   rule-based and (neural and non-neural) machine
                   learning-based reading comprehension models. Experimental
                   results on the DREAM dataset show the effectiveness of
                   dialogue structure and general world knowledge. DREAM will
                   be available at https://dataset.org/dream/.",
  month         =  feb,
  year          =  2019,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1902.00164"
}

@ARTICLE{Cui2020-nm,
  title         = "{MuTual}: A Dataset for {Multi-Turn} Dialogue Reasoning",
  author        = "Cui, Leyang and Wu, Yu and Liu, Shujie and Zhang, Yue and
                   Zhou, Ming",
  abstract      = "Non-task oriented dialogue systems have achieved great
                   success in recent years due to largely accessible
                   conversation data and the development of deep learning
                   techniques. Given a context, current systems are able to
                   yield a relevant and fluent response, but sometimes make
                   logical mistakes because of weak reasoning capabilities. To
                   facilitate the conversation reasoning research, we introduce
                   MuTual, a novel dataset for Multi-Turn dialogue Reasoning,
                   consisting of 8,860 manually annotated dialogues based on
                   Chinese student English listening comprehension exams.
                   Compared to previous benchmarks for non-task oriented
                   dialogue systems, MuTual is much more challenging since it
                   requires a model that can handle various reasoning problems.
                   Empirical results show that state-of-the-art methods only
                   reach 71\%, which is far behind the human performance of
                   94\%, indicating that there is ample room for improving
                   reasoning ability. MuTual is available at
                   https://github.com/Nealcly/MuTual.",
  month         =  apr,
  year          =  2020,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2004.04494"
}

@ARTICLE{Zahiri2017-sm,
  title         = "Emotion Detection on {TV} Show Transcripts with
                   Sequence-based Convolutional Neural Networks",
  author        = "Zahiri, Sayyed M and Choi, Jinho D",
  abstract      = "While there have been significant advances in detecting
                   emotions from speech and image recognition, emotion
                   detection on text is still under-explored and remained as an
                   active research field. This paper introduces a corpus for
                   text-based emotion detection on multiparty dialogue as well
                   as deep neural models that outperform the existing
                   approaches for document classification. We first present a
                   new corpus that provides annotation of seven emotions on
                   consecutive utterances in dialogues extracted from the show,
                   Friends. We then suggest four types of sequence-based
                   convolutional neural network models with attention that
                   leverage the sequence information encapsulated in dialogue.
                   Our best model shows the accuracies of 37.9\% and 54\% for
                   fine- and coarse-grained emotions, respectively. Given the
                   difficulty of this task, this is promising.",
  month         =  aug,
  year          =  2017,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1708.04299"
}

@ARTICLE{Devlin2018-om,
  title         = "{BERT}: Pre-training of Deep Bidirectional Transformers for
                   Language Understanding",
  author        = "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and
                   Toutanova, Kristina",
  abstract      = "We introduce a new language representation model called
                   BERT, which stands for Bidirectional Encoder Representations
                   from Transformers. Unlike recent language representation
                   models, BERT is designed to pre-train deep bidirectional
                   representations from unlabeled text by jointly conditioning
                   on both left and right context in all layers. As a result,
                   the pre-trained BERT model can be fine-tuned with just one
                   additional output layer to create state-of-the-art models
                   for a wide range of tasks, such as question answering and
                   language inference, without substantial task-specific
                   architecture modifications. BERT is conceptually simple and
                   empirically powerful. It obtains new state-of-the-art
                   results on eleven natural language processing tasks,
                   including pushing the GLUE score to 80.5\% (7.7\% point
                   absolute improvement), MultiNLI accuracy to 86.7\% (4.6\%
                   absolute improvement), SQuAD v1.1 question answering Test F1
                   to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test
                   F1 to 83.1 (5.1 point absolute improvement).",
  month         =  oct,
  year          =  2018,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1810.04805"
}

@ARTICLE{Bapna2017-qb,
  title         = "Sequential Dialogue Context Modeling for Spoken Language
                   Understanding",
  author        = "Bapna, Ankur and Tur, Gokhan and Hakkani-Tur, Dilek and
                   Heck, Larry",
  abstract      = "Spoken Language Understanding (SLU) is a key component of
                   goal oriented dialogue systems that would parse user
                   utterances into semantic frame representations.
                   Traditionally SLU does not utilize the dialogue history
                   beyond the previous system turn and contextual ambiguities
                   are resolved by the downstream components. In this paper, we
                   explore novel approaches for modeling dialogue context in a
                   recurrent neural network (RNN) based language understanding
                   system. We propose the Sequential Dialogue Encoder Network,
                   that allows encoding context from the dialogue history in
                   chronological order. We compare the performance of our
                   proposed architecture with two context models, one that uses
                   just the previous turn context and another that encodes
                   dialogue context in a memory network, but loses the order of
                   utterances in the dialogue history. Experiments with a
                   multi-domain dialogue dataset demonstrate that the proposed
                   architecture results in reduced semantic frame error rates.",
  month         =  may,
  year          =  2017,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1705.03455"
}

@ARTICLE{Ghosh2016-vt,
  title         = "Contextual {LSTM} ({CLSTM}) models for Large scale {NLP}
                   tasks",
  author        = "Ghosh, Shalini and Vinyals, Oriol and Strope, Brian and Roy,
                   Scott and Dean, Tom and Heck, Larry",
  abstract      = "Documents exhibit sequential structure at multiple levels of
                   abstraction (e.g., sentences, paragraphs, sections). These
                   abstractions constitute a natural hierarchy for representing
                   the context in which to infer the meaning of words and
                   larger fragments of text. In this paper, we present CLSTM
                   (Contextual LSTM), an extension of the recurrent neural
                   network LSTM (Long-Short Term Memory) model, where we
                   incorporate contextual features (e.g., topics) into the
                   model. We evaluate CLSTM on three specific NLP tasks: word
                   prediction, next sentence selection, and sentence topic
                   prediction. Results from experiments run on two corpora,
                   English documents in Wikipedia and a subset of articles from
                   a recent snapshot of English Google News, indicate that
                   using both words and topics as features improves performance
                   of the CLSTM models over baseline LSTM models for these
                   tasks. For example on the next sentence selection task, we
                   get relative accuracy improvements of 21\% for the Wikipedia
                   dataset and 18\% for the Google News dataset. This clearly
                   demonstrates the significant benefit of using context
                   appropriately in natural language (NL) tasks. This has
                   implications for a wide variety of NL applications like
                   question answering, sentence completion, paraphrase
                   generation, and next utterance prediction in dialog systems.",
  month         =  feb,
  year          =  2016,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1602.06291"
}

@INPROCEEDINGS{Balahur2011-xw,
  title     = "Detecting Implicit Expressions of Sentiment in Text Based on
               Commonsense Knowledge",
  booktitle = "Proceedings of the 2nd Workshop on Computational Approaches to
               Subjectivity and Sentiment Analysis ({{WASSA}} 2.011)",
  author    = "Balahur, Alexandra and Hermida, Jes{\'u}s M and Montoyo,
               Andr{\'e}s",
  publisher = "Association for Computational Linguistics",
  pages     = "53--60",
  month     =  jun,
  year      =  2011,
  address   = "Portland, Oregon",
  keywords  = "need to include in proposal outline;commonsense
               reasoning;thesis/prior work"
}

@ARTICLE{Siddique2021-bp,
  title         = "Generalized Zero-shot Intent Detection via Commonsense
                   Knowledge",
  author        = "Siddique, A B and Jamour, Fuad and Xu, Luxun and Hristidis,
                   Vagelis",
  abstract      = "Identifying user intents from natural language utterances is
                   a crucial step in conversational systems that has been
                   extensively studied as a supervised classification problem.
                   However, in practice, new intents emerge after deploying an
                   intent detection model. Thus, these models should seamlessly
                   adapt and classify utterances with both seen and unseen
                   intents -- unseen intents emerge after deployment and they
                   do not have training data. The few existing models that
                   target this setting rely heavily on the scarcely available
                   training data and overfit to seen intents data, resulting in
                   a bias to misclassify utterances with unseen intents into
                   seen ones. We propose RIDE: an intent detection model that
                   leverages commonsense knowledge in an unsupervised fashion
                   to overcome the issue of training data scarcity. RIDE
                   computes robust and generalizable relationship meta-features
                   that capture deep semantic relationships between utterances
                   and intent labels; these features are computed by
                   considering how the concepts in an utterance are linked to
                   those in an intent label via commonsense knowledge. Our
                   extensive experimental analysis on three widely-used intent
                   detection benchmarks shows that relationship meta-features
                   significantly increase the accuracy of detecting both seen
                   and unseen intents and that RIDE outperforms the
                   state-of-the-art model for unseen intents.",
  month         =  feb,
  year          =  2021,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2102.02925"
}

@ARTICLE{Jaech2016-rs,
  title         = "Domain Adaptation of Recurrent Neural Networks for Natural
                   Language Understanding",
  author        = "Jaech, Aaron and Heck, Larry and Ostendorf, Mari",
  abstract      = "The goal of this paper is to use multi-task learning to
                   efficiently scale slot filling models for natural language
                   understanding to handle multiple target tasks or domains.
                   The key to scalability is reducing the amount of training
                   data needed to learn a model for a new task. The proposed
                   multi-task model delivers better performance with less data
                   by leveraging patterns that it learns from the other tasks.
                   The approach supports an open vocabulary, which allows the
                   models to generalize to unseen words, which is particularly
                   important when very little training data is used. A newly
                   collected crowd-sourced data set, covering four different
                   domains, is used to demonstrate the effectiveness of the
                   domain adaptation and open vocabulary techniques.",
  month         =  apr,
  year          =  2016,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1604.00117"
}

@ARTICLE{Mesnil2015-hc,
  title     = "Using Recurrent Neural Networks for Slot Filling in Spoken
               Language Understanding",
  author    = "Mesnil, Gregoire and Dauphin, Yann and Yao, Kaisheng and Bengio,
               Yoshua and Zweig, Geoffrey",
  abstract  = "Semantic slot filling is one of the most challenging problems in
               spoken language understanding (SLU). In this paper, we propose
               to use recurrent neural networks (RNNs) for this task, and
               present several novel architectures designed to efficiently
               model past and future temporal dependencies. Specifically, we
               implemented and compared several important RNN architectures,
               including Elman, Jordan, and hybrid variants. To facilitate
               reproducibility, we implemented these networks with the publicly
               available Theano neural network toolkit and completed
               experiments on the well-known airline travel information system
               (ATIS) benchmark. In addition, we compared the approaches on two
               custom SLU data sets from the entertainment and movies domains.
               Our results show that the RNN-based models outperform the
               conditional random field (CRF) baseline by 2\% in absolute error
               reduction on the ATIS benchmark. We improve the state-of-the-art
               by 0.5\% in the Entertainment domain, and 6.7\% for the movies
               domain.",
  journal   = "IEEE/ACM Transactions on Audio Speech and Language Processing",
  publisher = "IEEE (Institute of Electrical and Electronics Engineers)",
  volume    =  23,
  number    =  3,
  pages     = "530--539",
  month     =  mar,
  year      =  2015,
  keywords  = "need to include in proposal outline;thesis/prior work"
}

@ARTICLE{Hwang2020-ow,
  title         = "{COMET-ATOMIC} 2020: On Symbolic and Neural Commonsense
                   Knowledge Graphs",
  author        = "Hwang, Jena D and Bhagavatula, Chandra and Le Bras, Ronan
                   and Da, Jeff and Sakaguchi, Keisuke and Bosselut, Antoine
                   and Choi, Yejin",
  abstract      = "Recent years have brought about a renewed interest in
                   commonsense representation and reasoning in the field of
                   natural language understanding. The development of new
                   commonsense knowledge graphs (CSKG) has been central to
                   these advances as their diverse facts can be used and
                   referenced by machine learning models for tackling new and
                   challenging tasks. At the same time, there remain questions
                   about the quality and coverage of these resources due to the
                   massive scale required to comprehensively encompass general
                   commonsense knowledge. In this work, we posit that manually
                   constructed CSKGs will never achieve the coverage necessary
                   to be applicable in all situations encountered by NLP
                   agents. Therefore, we propose a new evaluation framework for
                   testing the utility of KGs based on how effectively implicit
                   knowledge representations can be learned from them. With
                   this new goal, we propose ATOMIC 2020, a new CSKG of
                   general-purpose commonsense knowledge containing knowledge
                   that is not readily available in pretrained language models.
                   We evaluate its properties in comparison with other leading
                   CSKGs, performing the first large-scale pairwise study of
                   commonsense knowledge resources. Next, we show that ATOMIC
                   2020 is better suited for training knowledge models that can
                   generate accurate, representative knowledge for new, unseen
                   entities and events. Finally, through human evaluation, we
                   show that the few-shot performance of GPT-3 (175B
                   parameters), while impressive, remains ~12 absolute points
                   lower than a BART-based knowledge model trained on ATOMIC
                   2020 despite using over 430x fewer parameters.",
  month         =  oct,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2010.05953"
}

@ARTICLE{Vaswani2017-mo,
  title         = "Attention Is All You Need",
  author        = "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                   Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and
                   Kaiser, Lukasz and Polosukhin, Illia",
  abstract      = "The dominant sequence transduction models are based on
                   complex recurrent or convolutional neural networks in an
                   encoder-decoder configuration. The best performing models
                   also connect the encoder and decoder through an attention
                   mechanism. We propose a new simple network architecture, the
                   Transformer, based solely on attention mechanisms,
                   dispensing with recurrence and convolutions entirely.
                   Experiments on two machine translation tasks show these
                   models to be superior in quality while being more
                   parallelizable and requiring significantly less time to
                   train. Our model achieves 28.4 BLEU on the WMT 2014
                   English-to-German translation task, improving over the
                   existing best results, including ensembles by over 2 BLEU.
                   On the WMT 2014 English-to-French translation task, our
                   model establishes a new single-model state-of-the-art BLEU
                   score of 41.8 after training for 3.5 days on eight GPUs, a
                   small fraction of the training costs of the best models from
                   the literature. We show that the Transformer generalizes
                   well to other tasks by applying it successfully to English
                   constituency parsing both with large and limited training
                   data.",
  month         =  jun,
  year          =  2017,
  keywords      = "thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1706.03762"
}

@ARTICLE{Gao2018-ks,
  title         = "Neural Approaches to Conversational {AI}",
  author        = "Gao, Jianfeng and Galley, Michel and Li, Lihong",
  abstract      = "The present paper surveys neural approaches to
                   conversational AI that have been developed in the last few
                   years. We group conversational systems into three
                   categories: (1) question answering agents, (2) task-oriented
                   dialogue agents, and (3) chatbots. For each category, we
                   present a review of state-of-the-art neural approaches, draw
                   the connection between them and traditional approaches, and
                   discuss the progress that has been made and challenges still
                   being faced, using specific systems and models as case
                   studies.",
  month         =  sep,
  year          =  2018,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1809.08267"
}

@BOOK{Gordon2017-wf,
  title     = "A Formal Theory of Commonsense Psychology: How People Think
               People Think",
  author    = "Gordon, Andrew S and Hobbs, Jerry R",
  abstract  = "Commonsense psychology refers to the implicit theories that we
               all use to make sense of people's behavior in terms of their
               beliefs, goals, plans, and emotions. These are also the theories
               we employ when we anthropomorphize complex machines and
               computers as if they had humanlike mental lives. In order to
               successfully cooperate and communicate with people, these
               theories will need to be represented explicitly in future
               artificial intelligence systems. This book provides a
               large-scale logical formalization of commonsense psychology in
               support of humanlike artificial intelligence. It uses formal
               logic to encode the deep lexical semantics of the full breadth
               of psychological words and phrases, providing fourteen hundred
               axioms of first-order logic organized into twenty-nine
               commonsense psychology theories and sixteen background theories.
               This in-depth exploration of human commonsense reasoning for
               artificial intelligence researchers, linguists, and cognitive
               and social psychologists will serve as a foundation for the
               development of humanlike artificial intelligence.",
  publisher = "Cambridge University Press",
  month     =  sep,
  year      =  2017,
  keywords  = "commonsense reasoning;need to include in proposal
               outline;thesis/prior work",
  language  = "en"
}

@ARTICLE{Ilievski2021-ir,
  title    = "Dimensions of commonsense knowledge",
  author   = "Ilievski, Filip and Oltramari, Alessandro and Ma, Kaixin and
              Zhang, Bin and McGuinness, Deborah L and Szekely, Pedro",
  abstract = "Commonsense knowledge is essential for many AI applications,
              including those in natural language processing, visual
              processing, and planning. Consequently, many sources that include
              commonsense knowledge have been designed and constructed over the
              past decades. Recently, the focus has been on large text-based
              sources, which facilitate easier integration with neural
              (language) models and application to textual tasks, typically at
              the expense of the semantics of the sources and their
              harmonization. Efforts to consolidate commonsense knowledge have
              yielded partial success, with no clear path towards a
              comprehensive solution. We aim to organize these sources around a
              common set of dimensions of commonsense knowledge. We survey a
              wide range of popular commonsense sources with a special focus on
              their relations. We consolidate these relations into 13 knowledge
              dimensions. This consolidation allows us to unify the separate
              sources and to compute indications of their coverage, overlap,
              and gaps with respect to the knowledge dimensions. Moreover, we
              analyze the impact of each dimension on downstream reasoning
              tasks that require commonsense knowledge, observing that the
              temporal and desire/goal dimensions are very beneficial for
              reasoning on current downstream tasks, while distinctness and
              lexical knowledge have little impact. These results reveal
              preferences for some dimensions in current evaluation, and
              potential neglect of others.",
  journal  = "Knowledge-Based Systems",
  volume   =  229,
  pages    = "107347",
  month    =  oct,
  year     =  2021,
  keywords = "Commonsense knowledge; Semantics; Knowledge graphs;
              Reasoning;commonsense reasoning;thesis/prior work"
}

@ARTICLE{Liu2004-qg,
  title     = "{ConceptNet} --- A practical commonsense reasoning tool-kit",
  author    = "Liu, H and Singh, P",
  abstract  = "ConceptNet is a freely available commonsense knowledge base and
               natural-language-processing tool-kit which supports many
               practical textual-reasoning tasks over real-world documents
               including topic-gisting, analogy-making, and other context
               oriented inferences. The knowledge base is a semantic network
               presently consisting of over 1.6 million assertions of
               commonsense knowledge encompassing the spatial, physical,
               social, temporal, and psychological aspects of everyday life.
               ConceptNet is generated automatically from the 700 000 sentences
               of the Open Mind Common Sense Project --- a World Wide Web based
               collaboration with over 14 000 authors.",
  journal   = "BT Technol. J.",
  publisher = "Springer Nature",
  volume    =  22,
  number    =  4,
  pages     = "211--226",
  month     =  oct,
  year      =  2004,
  keywords  = "commonsense reasoning;need to include in proposal
               outline;thesis/prior work"
}

@ARTICLE{Storks2019-lb,
  title         = "Recent Advances in Natural Language Inference: A Survey of
                   Benchmarks, Resources, and Approaches",
  author        = "Storks, Shane and Gao, Qiaozi and Chai, Joyce Y",
  abstract      = "In the NLP community, recent years have seen a surge of
                   research activities that address machines' ability to
                   perform deep language understanding which goes beyond what
                   is explicitly stated in text, rather relying on reasoning
                   and knowledge of the world. Many benchmark tasks and
                   datasets have been created to support the development and
                   evaluation of such natural language inference ability. As
                   these benchmarks become instrumental and a driving force for
                   the NLP research community, this paper aims to provide an
                   overview of recent benchmarks, relevant knowledge resources,
                   and state-of-the-art learning and inference approaches in
                   order to support a better understanding of this growing
                   field.",
  month         =  apr,
  year          =  2019,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1904.01172"
}

@INPROCEEDINGS{Branco2021-tw,
  title     = "Shortcutted Commonsense: Data Spuriousness in Deep Learning of
               Commonsense Reasoning",
  booktitle = "Proceedings of the 2021 Conference on Empirical Methods in
               Natural Language Processing",
  author    = "Branco, Ruben and Branco, Ant{\'o}nio and Ant{\'o}nio Rodrigues,
               Jo{\~a}o and Silva, Jo{\~a}o Ricardo",
  abstract  = "Commonsense is a quintessential human capacity that has been a
               core challenge to Artificial Intelligence since its inception.
               Impressive results in Natural Language Processing tasks,
               including in commonsense reasoning, have consistently been
               achieved with Transformer neural language models, even matching
               or surpassing human performance in some benchmarks. Recently,
               some of these advances have been called into question: so called
               data artifacts in the training data have been made evident as
               spurious correlations and shallow shortcuts that in some cases
               are leveraging these outstanding results. In this paper we seek
               to further pursue this analysis into the realm of commonsense
               related language processing tasks. We undertake a study on
               different prominent benchmarks that involve commonsense
               reasoning, along a number of key stress experiments, thus
               seeking to gain insight on whether the models are learning
               transferable generalizations intrinsic to the problem at stake
               or just taking advantage of incidental shortcuts in the data
               items. The results obtained indicate that most datasets
               experimented with are problematic, with models resorting to
               non-robust features and appearing not to be learning and
               generalizing towards the overall tasks intended to be conveyed
               or exemplified by the datasets.",
  publisher = "Association for Computational Linguistics",
  pages     = "1504--1521",
  month     =  nov,
  year      =  2021,
  address   = "Online and Punta Cana, Dominican Republic",
  keywords  = "commonsense reasoning;thesis/prior work"
}

@ARTICLE{Reimers2019-xc,
  title         = "{Sentence-BERT}: Sentence Embeddings using Siamese
                   {BERT-Networks}",
  author        = "Reimers, Nils and Gurevych, Iryna",
  abstract      = "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019)
                   has set a new state-of-the-art performance on sentence-pair
                   regression tasks like semantic textual similarity (STS).
                   However, it requires that both sentences are fed into the
                   network, which causes a massive computational overhead:
                   Finding the most similar pair in a collection of 10,000
                   sentences requires about 50 million inference computations
                   (~65 hours) with BERT. The construction of BERT makes it
                   unsuitable for semantic similarity search as well as for
                   unsupervised tasks like clustering. In this publication, we
                   present Sentence-BERT (SBERT), a modification of the
                   pretrained BERT network that use siamese and triplet network
                   structures to derive semantically meaningful sentence
                   embeddings that can be compared using cosine-similarity.
                   This reduces the effort for finding the most similar pair
                   from 65 hours with BERT / RoBERTa to about 5 seconds with
                   SBERT, while maintaining the accuracy from BERT. We evaluate
                   SBERT and SRoBERTa on common STS tasks and transfer learning
                   tasks, where it outperforms other state-of-the-art sentence
                   embeddings methods.",
  month         =  aug,
  year          =  2019,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1908.10084"
}

@ARTICLE{West2021-de,
  title         = "Symbolic Knowledge Distillation: from General Language
                   Models to Commonsense Models",
  author        = "West, Peter and Bhagavatula, Chandra and Hessel, Jack and
                   Hwang, Jena D and Jiang, Liwei and Le Bras, Ronan and Lu,
                   Ximing and Welleck, Sean and Choi, Yejin",
  abstract      = "The common practice for training commonsense models has gone
                   from-human-to-corpus-to-machine: humans author commonsense
                   knowledge graphs in order to train commonsense models. In
                   this work, we investigate an alternative,
                   from-machine-to-corpus-to-machine: general language models
                   author these commonsense knowledge graphs to train
                   commonsense models. Our study leads to a new framework,
                   Symbolic Knowledge Distillation. As with prior art in
                   Knowledge Distillation (Hinton et al., 2015), our approach
                   uses larger models to teach smaller models. A key difference
                   is that we distill knowledge symbolically-as text-in
                   addition to the neural model. We also distill only one
                   aspect-the commonsense of a general language model teacher,
                   allowing the student to be a different type, a commonsense
                   model. Altogether, we show that careful prompt engineering
                   and a separately trained critic model allow us to
                   selectively distill high-quality causal commonsense from
                   GPT-3, a general language model. Empirical results
                   demonstrate that, for the first time, a human-authored
                   commonsense knowledge graph is surpassed by our
                   automatically distilled variant in all three criteria:
                   quantity, quality, and diversity. In addition, it results in
                   a neural commonsense model that surpasses the teacher
                   model's commonsense capabilities despite its 100x smaller
                   size. We apply this to the ATOMIC resource, and share our
                   new symbolic knowledge graph and commonsense models.",
  month         =  oct,
  year          =  2021,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2110.07178"
}

@ARTICLE{Li2021-qy,
  title         = "Conversations Are Not Flat: Modeling the Dynamic Information
                   Flow across Dialogue Utterances",
  author        = "Li, Zekang and Zhang, Jinchao and Fei, Zhengcong and Feng,
                   Yang and Zhou, Jie",
  abstract      = "Nowadays, open-domain dialogue models can generate
                   acceptable responses according to the historical context
                   based on the large-scale pre-trained language models.
                   However, they generally concatenate the dialogue history
                   directly as the model input to predict the response, which
                   we named as the flat pattern and ignores the dynamic
                   information flow across dialogue utterances. In this work,
                   we propose the DialoFlow model, in which we introduce a
                   dynamic flow mechanism to model the context flow, and design
                   three training objectives to capture the information
                   dynamics across dialogue utterances by addressing the
                   semantic influence brought about by each utterance in
                   large-scale pre-training. Experiments on the multi-reference
                   Reddit Dataset and DailyDialog Dataset demonstrate that our
                   DialoFlow significantly outperforms the DialoGPT on the
                   dialogue generation task. Besides, we propose the Flow
                   score, an effective automatic metric for evaluating
                   interactive human-bot conversation quality based on the
                   pre-trained DialoFlow, which presents high chatbot-level
                   correlation ($r=0.9$) with human ratings among 11 chatbots.
                   Code and pre-trained models will be public.
                   \textbackslashfootnote\{\textbackslashurl\{https://github.com/ictnlp/DialoFlow\}\}",
  month         =  jun,
  year          =  2021,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2106.02227"
}

@INCOLLECTION{Grice1975-fq,
  title     = "Logic and Conversation",
  booktitle = "The {Semantics-Pragmatics} Boundary in Philosophy",
  author    = "Grice, H Paul",
  editor    = "Ezcurdia, Maite and Stainton, Robert J",
  publisher = "Broadview Press",
  pages     = "47",
  year      =  1975,
  keywords  = "need to include in proposal outline;thesis/prior work"
}

@ARTICLE{Sap2019-ob,
  title     = "{ATOMIC}: An atlas of machine commonsense for if-then reasoning",
  author    = "Sap, Maarten and Le Bras, Ronan and Allaway, Emily and
               Bhagavatula, Chandra and Lourie, Nicholas and Rashkin, Hannah
               and Roof, Brendan and Smith, Noah A and Choi, Yejin",
  abstract  = "We present ATOMIC, an atlas of everyday commonsense reasoning,
               organized through 877k textual descriptions of inferential
               knowledge. Compared to existing resources that center around
               taxonomic knowledge, ATOMIC focuses on inferential knowledge
               organized as typed if-then relations with variables (e.g., ``if
               X pays Y a compliment, then Y will likely return the
               compliment''). We propose nine if-then relation types to
               distinguish causes vs. effects, agents vs. themes, voluntary vs.
               involuntary events, and actions vs. mental states. By
               generatively training on the rich inferential knowledge
               described in ATOMIC, we show that neural models can acquire
               simple commonsense capabilities and reason about previously
               unseen events. Experimental results demonstrate that multitask
               models that incorporate the hierarchical structure of if-then
               relation types lead to more accurate inference compared to
               models trained in isolation, as measured by both automatic and
               human evaluation.",
  journal   = "Proc. Conf. AAAI Artif. Intell.",
  publisher = "Association for the Advancement of Artificial Intelligence
               (AAAI)",
  volume    =  33,
  number    =  01,
  pages     = "3027--3035",
  month     =  jul,
  year      =  2019,
  keywords  = "commonsense reasoning;need to include in proposal
               outline;thesis/prior work"
}

@ARTICLE{Zhou2020-oa,
  title         = "{RICA}: Evaluating Robust Inference Capabilities Based on
                   Commonsense Axioms",
  author        = "Zhou, Pei and Khanna, Rahul and Lee, Seyeon and Lin, Bill
                   Yuchen and Ho, Daniel and Pujara, Jay and Ren, Xiang",
  abstract      = "Pre-trained language models (PTLMs) have achieved impressive
                   performance on commonsense inference benchmarks, but their
                   ability to employ commonsense to make robust inferences,
                   which is crucial for effective communications with humans,
                   is debated. In the pursuit of advancing fluid human-AI
                   communication, we propose a new challenge, RICA: Robust
                   Inference capability based on Commonsense Axioms, that
                   evaluates robust commonsense inference despite textual
                   perturbations. To generate data for this challenge, we
                   develop a systematic and scalable procedure using
                   commonsense knowledge bases and probe PTLMs across two
                   different evaluation settings. Extensive experiments on our
                   generated probe sets with more than 10k statements show that
                   PTLMs perform no better than random guessing on the
                   zero-shot setting, are heavily impacted by statistical
                   biases, and are not robust to perturbation attacks. We also
                   find that fine-tuning on similar statements offer limited
                   gains, as PTLMs still fail to generalize to unseen
                   inferences. Our new large-scale benchmark exposes a
                   significant gap between PTLMs and human-level language
                   understanding and offers a new challenge for PTLMs to
                   demonstrate commonsense.",
  month         =  may,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2005.00782"
}

@ARTICLE{Kim2022-lw,
  title         = "Modularized Transfer Learning with Multiple Knowledge Graphs
                   for Zero-shot Commonsense Reasoning",
  author        = "Kim, Yu Jin and Kwak, Beong-Woo and Kim, Youngwook and
                   Amplayo, Reinald Kim and Hwang, Seung-Won and Yeo, Jinyoung",
  abstract      = "Commonsense reasoning systems should be able to generalize
                   to diverse reasoning cases. However, most state-of-the-art
                   approaches depend on expensive data annotations and overfit
                   to a specific benchmark without learning how to perform
                   general semantic reasoning. To overcome these drawbacks,
                   zero-shot QA systems have shown promise as a robust learning
                   scheme by transforming a commonsense knowledge graph (KG)
                   into synthetic QA-form samples for model training.
                   Considering the increasing type of different commonsense
                   KGs, this paper aims to extend the zero-shot transfer
                   learning scenario into multiple-source settings, where
                   different KGs can be utilized synergetically. Towards this
                   goal, we propose to mitigate the loss of knowledge from the
                   interference among the different knowledge sources, by
                   developing a modular variant of the knowledge aggregation as
                   a new zero-shot commonsense reasoning framework. Results on
                   five commonsense reasoning benchmarks demonstrate the
                   efficacy of our framework, improving the performance with
                   multiple KGs.",
  month         =  jun,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2206.03715"
}

@ARTICLE{Wang2021-rj,
  title         = "Retrieval Enhanced Model for Commonsense Generation",
  author        = "Wang, Han and Liu, Yang and Zhu, Chenguang and Shou, Linjun
                   and Gong, Ming and Xu, Yichong and Zeng, Michael",
  abstract      = "Commonsense generation is a challenging task of generating a
                   plausible sentence describing an everyday scenario using
                   provided concepts. Its requirement of reasoning over
                   commonsense knowledge and compositional generalization
                   ability even puzzles strong pre-trained language generation
                   models. We propose a novel framework using retrieval methods
                   to enhance both the pre-training and fine-tuning for
                   commonsense generation. We retrieve prototype sentence
                   candidates by concept matching and use them as auxiliary
                   input. For fine-tuning, we further boost its performance
                   with a trainable sentence retriever. We demonstrate
                   experimentally on the large-scale CommonGen benchmark that
                   our approach achieves new state-of-the-art results.",
  month         =  may,
  year          =  2021,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2105.11174"
}

@ARTICLE{Chang2021-tb,
  title         = "Incorporating Commonsense Knowledge Graph in Pretrained
                   Models for Social Commonsense Tasks",
  author        = "Chang, Ting-Yun and Liu, Yang and Gopalakrishnan, Karthik
                   and Hedayatnia, Behnam and Zhou, Pei and Hakkani-Tur, Dilek",
  abstract      = "Pretrained language models have excelled at many NLP tasks
                   recently; however, their social intelligence is still
                   unsatisfactory. To enable this, machines need to have a more
                   general understanding of our complicated world and develop
                   the ability to perform commonsense reasoning besides fitting
                   the specific downstream tasks. External commonsense
                   knowledge graphs (KGs), such as ConceptNet, provide rich
                   information about words and their relationships. Thus,
                   towards general commonsense learning, we propose two
                   approaches to \textbackslashemph\{implicitly\} and
                   \textbackslashemph\{explicitly\} infuse such KGs into
                   pretrained language models. We demonstrate our proposed
                   methods perform well on SocialIQA, a social commonsense
                   reasoning task, in both limited and full training data
                   regimes.",
  month         =  may,
  year          =  2021,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2105.05457"
}

@ARTICLE{Liu2020-ia,
  title         = "Commonsense Evidence Generation and Injection in Reading
                   Comprehension",
  author        = "Liu, Ye and Yang, Tao and You, Zeyu and Fan, Wei and Yu,
                   Philip S",
  abstract      = "Human tackle reading comprehension not only based on the
                   given context itself but often rely on the commonsense
                   beyond. To empower the machine with commonsense reasoning,
                   in this paper, we propose a Commonsense Evidence Generation
                   and Injection framework in reading comprehension, named
                   CEGI. The framework injects two kinds of auxiliary
                   commonsense evidence into comprehensive reading to equip the
                   machine with the ability of rational thinking. Specifically,
                   we build two evidence generators: the first generator aims
                   to generate textual evidence via a language model; the other
                   generator aims to extract factual evidence (automatically
                   aligned text-triples) from a commonsense knowledge graph
                   after graph completion. Those evidences incorporate
                   contextual commonsense and serve as the additional inputs to
                   the model. Thereafter, we propose a deep contextual encoder
                   to extract semantic relationships among the paragraph,
                   question, option, and evidence. Finally, we employ a capsule
                   network to extract different linguistic units (word and
                   phrase) from the relations, and dynamically predict the
                   optimal option based on the extracted units. Experiments on
                   the CosmosQA dataset demonstrate that the proposed CEGI
                   model outperforms the current state-of-the-art approaches
                   and achieves the accuracy (83.6\%) on the leaderboard.",
  month         =  may,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2005.05240"
}

@ARTICLE{Bosselut2021-li,
  title    = "Dynamic {Neuro-Symbolic} Knowledge Graph Construction for
              Zero-shot Commonsense Question Answering",
  author   = "Bosselut, Antoine and Le Bras, Ronan and Choi, Yejin",
  abstract = "Understanding narratives requires reasoning about implicit world
              knowledge related to the causes, effects, and states of
              situations described in text. At the core of this challenge is
              how to access contextually relevant knowledge on demand and
              reason over it. In this paper, we present initial studies toward
              zero-shot commonsense question answering by formulating the task
              as inference over dynamically generated commonsense knowledge
              graphs. In contrast to previous studies for knowledge integration
              that rely on retrieval of existing knowledge from static
              knowledge graphs, our study requires commonsense knowledge
              integration where contextually relevant knowledge is often not
              present in existing knowledge bases. Therefore, we present a
              novel approach that generates contextually-relevant symbolic
              knowledge structures on demand using generative neural
              commonsense knowledge models. Empirical results on two datasets
              demonstrate the efficacy of our neuro-symbolic approach for
              dynamically constructing knowledge graphs for reasoning. Our
              approach achieves significant performance boosts over pretrained
              language models and vanilla knowledge models, all while providing
              interpretable reasoning paths for its predictions.",
  journal  = "AAAI",
  volume   =  35,
  number   =  6,
  pages    = "4923--4931",
  month    =  may,
  year     =  2021,
  keywords = "Neuro-Symbolic AI (NSAI);commonsense reasoning;thesis/prior work",
  language = "en"
}

@ARTICLE{Butlin2023-jm,
  title         = "Consciousness in Artificial Intelligence: Insights from the
                   Science of Consciousness",
  author        = "Butlin, Patrick and Long, Robert and Elmoznino, Eric and
                   Bengio, Yoshua and Birch, Jonathan and Constant, Axel and
                   Deane, George and Fleming, Stephen M and Frith, Chris and
                   Ji, Xu and Kanai, Ryota and Klein, Colin and Lindsay, Grace
                   and Michel, Matthias and Mudrik, Liad and Peters, Megan A K
                   and Schwitzgebel, Eric and Simon, Jonathan and VanRullen,
                   Rufin",
  abstract      = "Whether current or near-term AI systems could be conscious
                   is a topic of scientific interest and increasing public
                   concern. This report argues for, and exemplifies, a rigorous
                   and empirically grounded approach to AI consciousness:
                   assessing existing AI systems in detail, in light of our
                   best-supported neuroscientific theories of consciousness. We
                   survey several prominent scientific theories of
                   consciousness, including recurrent processing theory, global
                   workspace theory, higher-order theories, predictive
                   processing, and attention schema theory. From these theories
                   we derive ``indicator properties'' of consciousness,
                   elucidated in computational terms that allow us to assess AI
                   systems for these properties. We use these indicator
                   properties to assess several recent AI systems, and we
                   discuss how future systems might implement them. Our
                   analysis suggests that no current AI systems are conscious,
                   but also shows that there are no obvious barriers to
                   building conscious AI systems.",
  month         =  aug,
  year          =  2023,
  keywords      = "machine consciousness;reading list;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2308.08708"
}

@ARTICLE{Kim2022-pz,
  title         = "Mind the Gap! Injecting Commonsense Knowledge for
                   Abstractive Dialogue Summarization",
  author        = "Kim, Seungone and Joo, Se June and Chae, Hyungjoo and Kim,
                   Chaehyeong and Hwang, Seung-Won and Yeo, Jinyoung",
  abstract      = "In this paper, we propose to leverage the unique
                   characteristics of dialogues sharing commonsense knowledge
                   across participants, to resolve the difficulties in
                   summarizing them. We present SICK, a framework that uses
                   commonsense inferences as additional context. Compared to
                   previous work that solely relies on the input dialogue, SICK
                   uses an external knowledge model to generate a rich set of
                   commonsense inferences and selects the most probable one
                   with a similarity-based selection method. Built upon SICK,
                   SICK++ utilizes commonsense as supervision, where the task
                   of generating commonsense inferences is added upon
                   summarizing the dialogue in a multi-task learning setting.
                   Experimental results show that with injected commonsense
                   knowledge, our framework generates more informative and
                   consistent summaries than existing methods.",
  month         =  sep,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2209.00930"
}

@ARTICLE{Arabshahi2021-ly,
  title         = "Conversational {Multi-Hop} Reasoning with Neural Commonsense
                   Knowledge and Symbolic Logic Rules",
  author        = "Arabshahi, Forough and Lee, Jennifer and Bosselut, Antoine
                   and Choi, Yejin and Mitchell, Tom",
  abstract      = "One of the challenges faced by conversational agents is
                   their inability to identify unstated presumptions of their
                   users' commands, a task trivial for humans due to their
                   common sense. In this paper, we propose a zero-shot
                   commonsense reasoning system for conversational agents in an
                   attempt to achieve this. Our reasoner uncovers unstated
                   presumptions from user commands satisfying a general
                   template of if-(state), then-(action), because-(goal). Our
                   reasoner uses a state-of-the-art transformer-based
                   generative commonsense knowledge base (KB) as its source of
                   background knowledge for reasoning. We propose a novel and
                   iterative knowledge query mechanism to extract multi-hop
                   reasoning chains from the neural KB which uses symbolic
                   logic rules to significantly reduce the search space.
                   Similar to any KBs gathered to date, our commonsense KB is
                   prone to missing knowledge. Therefore, we propose to
                   conversationally elicit the missing knowledge from human
                   users with our novel dynamic question generation strategy,
                   which generates and presents contextualized queries to human
                   users. We evaluate the model with a user study with human
                   users that achieves a 35\% higher success rate compared to
                   SOTA.",
  month         =  sep,
  year          =  2021,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2109.08544"
}

@ARTICLE{Li2022-jr,
  title         = "Neutral Utterances are Also Causes: Enhancing Conversational
                   Causal Emotion Entailment with Social Commonsense Knowledge",
  author        = "Li, Jiangnan and Meng, Fandong and Lin, Zheng and Liu, Rui
                   and Fu, Peng and Cao, Yanan and Wang, Weiping and Zhou, Jie",
  abstract      = "Conversational Causal Emotion Entailment aims to detect
                   causal utterances for a non-neutral targeted utterance from
                   a conversation. In this work, we build conversations as
                   graphs to overcome implicit contextual modelling of the
                   original entailment style. Following the previous work, we
                   further introduce the emotion information into graphs.
                   Emotion information can markedly promote the detection of
                   causal utterances whose emotion is the same as the targeted
                   utterance. However, it is still hard to detect causal
                   utterances with different emotions, especially neutral ones.
                   The reason is that models are limited in reasoning causal
                   clues and passing them between utterances. To alleviate this
                   problem, we introduce social commonsense knowledge (CSK) and
                   propose a Knowledge Enhanced Conversation graph (KEC). KEC
                   propagates the CSK between two utterances. As not all CSK is
                   emotionally suitable for utterances, we therefore propose a
                   sentiment-realized knowledge selecting strategy to filter
                   CSK. To process KEC, we further construct the Knowledge
                   Enhanced Directed Acyclic Graph networks. Experimental
                   results show that our method outperforms baselines and
                   infers more causes with different emotions from the targeted
                   utterance.",
  month         =  may,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2205.00759"
}

@ARTICLE{Ghosal2020-ll,
  title         = "{COSMIC}: {COmmonSense} knowledge for eMotion Identification
                   in Conversations",
  author        = "Ghosal, Deepanway and Majumder, Navonil and Gelbukh,
                   Alexander and Mihalcea, Rada and Poria, Soujanya",
  abstract      = "In this paper, we address the task of utterance level
                   emotion recognition in conversations using commonsense
                   knowledge. We propose COSMIC, a new framework that
                   incorporates different elements of commonsense such as
                   mental states, events, and causal relations, and build upon
                   them to learn interactions between interlocutors
                   participating in a conversation. Current state-of-the-art
                   methods often encounter difficulties in context propagation,
                   emotion shift detection, and differentiating between related
                   emotion classes. By learning distinct commonsense
                   representations, COSMIC addresses these challenges and
                   achieves new state-of-the-art results for emotion
                   recognition on four different benchmark conversational
                   datasets. Our code is available at
                   https://github.com/declare-lab/conv-emotion.",
  month         =  oct,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2010.02795"
}

@ARTICLE{Ghosal2021-ly,
  title         = "{CIDER}: Commonsense Inference for Dialogue Explanation and
                   Reasoning",
  author        = "Ghosal, Deepanway and Hong, Pengfei and Shen, Siqi and
                   Majumder, Navonil and Mihalcea, Rada and Poria, Soujanya",
  abstract      = "Commonsense inference to understand and explain human
                   language is a fundamental research problem in natural
                   language processing. Explaining human conversations poses a
                   great challenge as it requires contextual understanding,
                   planning, inference, and several aspects of reasoning
                   including causal, temporal, and commonsense reasoning. In
                   this work, we introduce CIDER -- a manually curated dataset
                   that contains dyadic dialogue explanations in the form of
                   implicit and explicit knowledge triplets inferred using
                   contextual commonsense inference. Extracting such rich
                   explanations from conversations can be conducive to
                   improving several downstream applications. The annotated
                   triplets are categorized by the type of commonsense
                   knowledge present (e.g., causal, conditional, temporal). We
                   set up three different tasks conditioned on the annotated
                   dataset: Dialogue-level Natural Language Inference, Span
                   Extraction, and Multi-choice Span Selection. Baseline
                   results obtained with transformer-based models reveal that
                   the tasks are difficult, paving the way for promising future
                   research. The dataset and the baseline implementations are
                   publicly available at https://cider-task.github.io/cider/.",
  month         =  jun,
  year          =  2021,
  keywords      = "dataset;commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2106.00510"
}

@ARTICLE{Gabriel2021-nv,
  title    = "Paragraph-level Commonsense Transformers with Recurrent Memory",
  author   = "Gabriel, Saadia and Bhagavatula, Chandra and Shwartz, Vered and
              Le Bras, Ronan and Forbes, Maxwell and Choi, Yejin",
  abstract = "Human understanding of narrative texts requires making
              commonsense inferences beyond what is stated in the text
              explicitly. A recent model, COMET, can generate such inferences
              along several dimensions such as pre- and post-conditions,
              motivations, and mental states of the participants. However,
              COMET was trained on short phrases, and is therefore
              discourse-agnostic. When presented with each sentence of a
              multi-sentence narrative, it might generate inferences that are
              inconsistent with the rest of the narrative. We present the task
              of discourse-aware commonsense inference. Given a sentence within
              a narrative, the goal is to generate commonsense inferences along
              predefined dimensions, while maintaining coherence with the rest
              of the narrative. Such large-scale paragraph-level annotation is
              hard to get and costly, so we use available sentence-level
              annotations to efficiently and automatically construct a
              distantly supervised corpus. Using this corpus, we train
              PARA-COMET, a discourse-aware model that incorporates
              paragraph-level information to generate coherent commonsense
              inferences from narratives. PARA-COMET captures both semantic
              knowledge pertaining to prior world knowledge, and episodic
              knowledge involving how current events relate to prior and future
              events in a narrative. Our results confirm that PARA-COMET
              outperforms the sentence-level baselines, particularly in
              generating inferences that are both coherent and novel.",
  journal  = "AAAI",
  volume   =  35,
  number   =  14,
  pages    = "12857--12865",
  month    =  may,
  year     =  2021,
  keywords = "Generation; Common-Sense Reasoning; Social Cognition And
              Interaction; Discourse, Pragmatics \& Argument Mining;commonsense
              reasoning;thesis/prior work",
  language = "en"
}

@ARTICLE{Bosselut2019-he,
  title         = "{COMET}: Commonsense Transformers for Automatic Knowledge
                   Graph Construction",
  author        = "Bosselut, Antoine and Rashkin, Hannah and Sap, Maarten and
                   Malaviya, Chaitanya and Celikyilmaz, Asli and Choi, Yejin",
  abstract      = "We present the first comprehensive study on automatic
                   knowledge base construction for two prevalent commonsense
                   knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet
                   (Speer et al., 2017). Contrary to many conventional KBs that
                   store knowledge with canonical templates, commonsense KBs
                   only store loosely structured open-text descriptions of
                   knowledge. We posit that an important step toward automatic
                   commonsense completion is the development of generative
                   models of commonsense knowledge, and propose COMmonsEnse
                   Transformers (COMET) that learn to generate rich and diverse
                   commonsense descriptions in natural language. Despite the
                   challenges of commonsense modeling, our investigation
                   reveals promising results when implicit knowledge from deep
                   pre-trained language models is transferred to generate
                   explicit knowledge in commonsense knowledge graphs.
                   Empirical results demonstrate that COMET is able to generate
                   novel knowledge that humans rate as high quality, with up to
                   77.5\% (ATOMIC) and 91.7\% (ConceptNet) precision at top 1,
                   which approaches human performance for these resources. Our
                   findings suggest that using generative commonsense models
                   for automatic commonsense KB completion could soon be a
                   plausible alternative to extractive methods.",
  month         =  jun,
  year          =  2019,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1906.05317"
}

@ARTICLE{Gupta2022-bs,
  title         = "{Target-Guided} Dialogue Response Generation Using
                   Commonsense and Data Augmentation",
  author        = "Gupta, Prakhar and Jhamtani, Harsh and Bigham, Jeffrey P",
  abstract      = "Target-guided response generation enables dialogue systems
                   to smoothly transition a conversation from a dialogue
                   context toward a target sentence. Such control is useful for
                   designing dialogue systems that direct a conversation toward
                   specific goals, such as creating non-obtrusive
                   recommendations or introducing new topics in the
                   conversation. In this paper, we introduce a new technique
                   for target-guided response generation, which first finds a
                   bridging path of commonsense knowledge concepts between the
                   source and the target, and then uses the identified bridging
                   path to generate transition responses. Additionally, we
                   propose techniques to re-purpose existing dialogue datasets
                   for target-guided generation. Experiments reveal that the
                   proposed techniques outperform various baselines on this
                   task. Finally, we observe that the existing automated
                   metrics for this task correlate poorly with human judgement
                   ratings. We propose a novel evaluation metric that we
                   demonstrate is more reliable for target-guided response
                   evaluation. Our work generally enables dialogue system
                   designers to exercise more control over the conversations
                   that their systems produce.",
  month         =  may,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2205.09314"
}

@ARTICLE{Xu2022-fv,
  title         = "Open-domain Dialogue Generation Grounded with Dynamic
                   Multi-form Knowledge Fusion",
  author        = "Xu, Feifei and Zhou, Shanlin and Wang, Xinpeng and Ma, Yunpu
                   and Zhang, Wenkai and Li, Zhisong",
  abstract      = "Open-domain multi-turn conversations normally face the
                   challenges of how to enrich and expand the content of the
                   conversation. Recently, many approaches based on external
                   knowledge are proposed to generate rich semantic and
                   information conversation. Two types of knowledge have been
                   studied for knowledge-aware open-domain dialogue generation:
                   structured triples from knowledge graphs and unstructured
                   texts from documents. To take both advantages of abundant
                   unstructured latent knowledge in the documents and the
                   information expansion capabilities of the structured
                   knowledge graph, this paper presents a new dialogue
                   generation model, Dynamic Multi-form Knowledge Fusion based
                   Open-domain Chatt-ing Machine (DMKCM).In particular, DMKCM
                   applies an indexed text (a virtual Knowledge Base) to locate
                   relevant documents as 1st hop and then expands the content
                   of the dialogue and its 1st hop using a commonsense
                   knowledge graph to get apposite triples as 2nd hop. To merge
                   these two forms of knowledge into the dialogue effectively,
                   we design a dynamic virtual knowledge selector and a
                   controller that help to enrich and expand knowledge space.
                   Moreover, DMKCM adopts a novel dynamic knowledge memory
                   module that effectively uses historical reasoning knowledge
                   to generate better responses. Experimental results indicate
                   the effectiveness of our method in terms of dialogue
                   coherence and informativeness.",
  month         =  apr,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2204.11239"
}

@ARTICLE{Varshney2022-ly,
  title         = "Commonsense and Named Entity Aware Knowledge Grounded
                   Dialogue Generation",
  author        = "Varshney, Deeksha and Prabhakar, Akshara and Ekbal, Asif",
  abstract      = "Grounding dialogue on external knowledge and interpreting
                   linguistic patterns in dialogue history context, such as
                   ellipsis, anaphora, and co-references is critical for
                   dialogue comprehension and generation. In this paper, we
                   present a novel open-domain dialogue generation model which
                   effectively utilizes the large-scale commonsense and named
                   entity based knowledge in addition to the unstructured
                   topic-specific knowledge associated with each utterance. We
                   enhance the commonsense knowledge with named entity-aware
                   structures using co-references. Our proposed model utilizes
                   a multi-hop attention layer to preserve the most accurate
                   and critical parts of the dialogue history and the
                   associated knowledge. In addition, we employ a Commonsense
                   and Named Entity Enhanced Attention Module, which starts
                   with the extracted triples from various sources and
                   gradually finds the relevant supporting set of triples using
                   multi-hop attention with the query vector obtained from the
                   interactive dialogue-knowledge module. Empirical results on
                   two benchmark dataset demonstrate that our model
                   significantly outperforms the state-of-the-art methods in
                   terms of both automatic evaluation metrics and human
                   judgment. Our code is publicly available at
                   \textbackslashhref\{https://github.com/deekshaVarshney/CNTF\}\{https://github.com/deekshaVarshney/CNTF\};
                   \textbackslashhref\{https://www.iitp.ac.in/~ai-nlp-ml/resources/codes/CNTF.zip\}\{https://www.iitp.ac.in/-ai-nlp-ml/resources/
                   codes/CNTF.zip\}.",
  month         =  may,
  year          =  2022,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2205.13928"
}

@INPROCEEDINGS{Wu2020-mq,
  title     = "Diverse and Informative Dialogue Generation with
               {Context-Specific} Commonsense Knowledge Awareness",
  booktitle = "Proceedings of the 58th Annual Meeting of the Association for
               Computational Linguistics",
  author    = "Wu, Sixing and Li, Ying and Zhang, Dawei and Zhou, Yang and Wu,
               Zhonghai",
  abstract  = "Generative dialogue systems tend to produce generic responses,
               which often leads to boring conversations. For alleviating this
               issue, Recent studies proposed to retrieve and introduce
               knowledge facts from knowledge graphs. While this paradigm works
               to a certain extent, it usually retrieves knowledge facts only
               based on the entity word itself, without considering the
               specific dialogue context. Thus, the introduction of the
               context-irrelevant knowledge facts can impact the quality of
               generations. To this end, this paper proposes a novel
               commonsense knowledge-aware dialogue generation model, ConKADI.
               We design a Felicitous Fact mechanism to help the model focus on
               the knowledge facts that are highly relevant to the context;
               furthermore, two techniques, Context-Knowledge Fusion and
               Flexible Mode Fusion are proposed to facilitate the integration
               of the knowledge in the ConKADI. We collect and build a
               large-scale Chinese dataset aligned with the commonsense
               knowledge for dialogue generation. Extensive evaluations over
               both an open-released English dataset and our Chinese dataset
               demonstrate that our approach ConKADI outperforms the
               state-of-the-art approach CCM, in most experiments.",
  publisher = "Association for Computational Linguistics",
  pages     = "5811--5820",
  month     =  jul,
  year      =  2020,
  address   = "Online",
  keywords  = "commonsense reasoning;need to include in proposal
               outline;thesis/prior work"
}

@ARTICLE{Feng2020-jk,
  title         = "Incorporating Commonsense Knowledge into Abstractive
                   Dialogue Summarization via Heterogeneous Graph Networks",
  author        = "Feng, Xiachong and Feng, Xiaocheng and Qin, Bing and Liu,
                   Ting",
  abstract      = "Abstractive dialogue summarization is the task of capturing
                   the highlights of a dialogue and rewriting them into a
                   concise version. In this paper, we present a novel
                   multi-speaker dialogue summarizer to demonstrate how
                   large-scale commonsense knowledge can facilitate dialogue
                   understanding and summary generation. In detail, we consider
                   utterance and commonsense knowledge as two different types
                   of data and design a Dialogue Heterogeneous Graph Network
                   (D-HGN) for modeling both information. Meanwhile, we also
                   add speakers as heterogeneous nodes to facilitate
                   information flow. Experimental results on the SAMSum dataset
                   show that our model can outperform various methods. We also
                   conduct zero-shot setting experiments on the Argumentative
                   Dialogue Summary Corpus, the results show that our model can
                   better generalized to the new domain.",
  month         =  oct,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2010.10044"
}

@ARTICLE{Velickovic2017-mo,
  title         = "Graph Attention Networks",
  author        = "Veli{\v c}kovi{\'c}, Petar and Cucurull, Guillem and
                   Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro
                   and Bengio, Yoshua",
  abstract      = "We present graph attention networks (GATs), novel neural
                   network architectures that operate on graph-structured data,
                   leveraging masked self-attentional layers to address the
                   shortcomings of prior methods based on graph convolutions or
                   their approximations. By stacking layers in which nodes are
                   able to attend over their neighborhoods' features, we enable
                   (implicitly) specifying different weights to different nodes
                   in a neighborhood, without requiring any kind of costly
                   matrix operation (such as inversion) or depending on knowing
                   the graph structure upfront. In this way, we address several
                   key challenges of spectral-based graph neural networks
                   simultaneously, and make our model readily applicable to
                   inductive as well as transductive problems. Our GAT models
                   have achieved or matched state-of-the-art results across
                   four established transductive and inductive graph
                   benchmarks: the Cora, Citeseer and Pubmed citation network
                   datasets, as well as a protein-protein interaction dataset
                   (wherein test graphs remain unseen during training).",
  month         =  oct,
  year          =  2017,
  keywords      = "need to include in proposal outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "1710.10903"
}

@ARTICLE{Tu2022-fe,
  title    = "Sentiment- Emotion- and Context-guided Knowledge Selection
              Framework for Emotion Recognition in Conversations",
  author   = "Tu, Geng and Liang, Bin and Jiang, Dazhi and Xu, Ruifeng",
  abstract = "Emotion recognition in conversations (ERC) needs to detect the
              emotion of each utterance in conversations. However, it is
              difficult for machines to recognize the emotion of utterances
              like humans, partly because of the lack of commonsense knowledge.
              Despite existing efforts gradually incorporate knowledge in ERC,
              they can not adaptively adjust knowledge according to different
              utterances and their context. In this paper, we propose a
              knowledge selection framework SKSEC (Select Knowledge in light of
              Sentiment Emotion and Context). In the SKSEC framework, firstly,
              external knowledge is eliminated by three Knowledge Elimination
              (KE) modules. More concretely, In word-level KE, the concept
              knowledge different from the sentiment corresponding to the word
              in utterances is randomly eliminated. In utterance- or
              context-level KE, If the similarity between the knowledge
              representation and the emotion label representation of the
              current utterance or its context is less than the preset
              threshold, the knowledge will be eliminated. Then we refine the
              weight of knowledge using two Graph ATtention (GAT) mechanisms.
              Specifically, In Sentics GAT, we employ a dimensional emotion
              model to measure words in utterances and their corresponding
              knowledge and adjust the weight of knowledge according to their
              emotional similarity. In Semantics GAT, the weight of knowledge
              is adjusted according to the semantic similarity between context
              and incorporated knowledge. Finally, we feed the selected
              knowledge to the most advanced models to evaluate the quality of
              knowledge. The experimental results show that the SKSEC framework
              can effectively improve the performance of the model by
              eliminating and refining external knowledge in different size and
              domain datasets.",
  journal  = "IEEE Transactions on Affective Computing",
  pages    = "1--14",
  year     =  2022,
  keywords = "Emotion recognition;Context modeling;Semantics;Knowledge based
              systems;Psychology;Oral communication;Computer
              science;Conversational emotion recognition;knowledge
              elimination;knowledge refinement;commonsense
              reasoning;thesis/prior work"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Moon2019-ws,
  title     = "Opendialkg: Explainable conversational reasoning with
               attention-based walks over knowledge graphs",
  author    = "Moon, S and Shah, P and Kumar, A and Subba, R",
  abstract  = "We study a conversational reasoning model that strategically
               traverses through a large- scale common fact knowledge graph
               (KG) to introduce engaging and contextually diverse entities and
               attributes. For this study, we collect a new Open-ended Dialog
               KG parallel corpus called OpenDialKG, where each utterance from
               15K human-to-human role-playing dialogs is manually annotated
               with ground-truth reference to corresponding entities and paths
               from a large-scale KG with 1M+ facts. We then propose the DialKG
               Walker model that ",
  journal   = "Proceedings of the 57th",
  publisher = "aclanthology.org",
  year      =  2019,
  keywords  = "commonsense reasoning;need to include in proposal
               outline;thesis/prior work"
}

@ARTICLE{Ma2020-eh,
  title         = "Knowledge-driven Data Construction for Zero-shot Evaluation
                   in Commonsense Question Answering",
  author        = "Ma, Kaixin and Ilievski, Filip and Francis, Jonathan and
                   Bisk, Yonatan and Nyberg, Eric and Oltramari, Alessandro",
  abstract      = "Recent developments in pre-trained neural language modeling
                   have led to leaps in accuracy on commonsense
                   question-answering benchmarks. However, there is increasing
                   concern that models overfit to specific tasks, without
                   learning to utilize external knowledge or perform general
                   semantic reasoning. In contrast, zero-shot evaluations have
                   shown promise as a more robust measure of a model's general
                   reasoning abilities. In this paper, we propose a novel
                   neuro-symbolic framework for zero-shot question answering
                   across commonsense tasks. Guided by a set of hypotheses, the
                   framework studies how to transform various pre-existing
                   knowledge resources into a form that is most effective for
                   pre-training models. We vary the set of language models,
                   training regimes, knowledge sources, and data generation
                   strategies, and measure their impact across tasks. Extending
                   on prior work, we devise and compare four constrained
                   distractor-sampling strategies. We provide empirical results
                   across five commonsense question-answering tasks with data
                   generated from five external knowledge resources. We show
                   that, while an individual knowledge graph is better suited
                   for specific tasks, a global knowledge graph brings
                   consistent gains across different tasks. In addition, both
                   preserving the structure of the task as well as generating
                   fair and informative questions help language models learn
                   more effectively.",
  month         =  nov,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2011.03863"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Young2018-kb,
  title     = "Augmenting end-to-end dialogue systems with commonsense
               knowledge",
  author    = "Young, T and Cambria, E and Chaturvedi, I and Zhou, H and
               {others}",
  abstract  = "Building dialogue systems that can converse naturally with
               humans is a challenging yet intriguing problem of artificial
               intelligence. In open-domain human-computer conversation, where
               the conversational agent is expected to respond to human
               utterances in an interesting and engaging way, commonsense
               knowledge has to be integrated into the model effectively. In
               this paper, we investigate the impact of providing commonsense
               knowledge about the concepts covered in the dialogue. Our model
               represents the first ",
  journal   = "Proceedings of the",
  publisher = "ojs.aaai.org",
  year      =  2018,
  keywords  = "commonsense reasoning;need to include in proposal
               outline;thesis/prior work"
}

@ARTICLE{Majumder2020-pz,
  title         = "Like hiking? You probably enjoy nature: Persona-grounded
                   Dialog with Commonsense Expansions",
  author        = "Majumder, Bodhisattwa Prasad and Jhamtani, Harsh and
                   Berg-Kirkpatrick, Taylor and McAuley, Julian",
  abstract      = "Existing persona-grounded dialog models often fail to
                   capture simple implications of given persona descriptions,
                   something which humans are able to do seamlessly. For
                   example, state-of-the-art models cannot infer that interest
                   in hiking might imply love for nature or longing for a
                   break. In this paper, we propose to expand available persona
                   sentences using existing commonsense knowledge bases and
                   paraphrasing resources to imbue dialog models with access to
                   an expanded and richer set of persona descriptions.
                   Additionally, we introduce fine-grained grounding on
                   personas by encouraging the model to make a discrete choice
                   among persona sentences while synthesizing a dialog
                   response. Since such a choice is not observed in the data,
                   we model it using a discrete latent random variable and use
                   variational learning to sample from hundreds of persona
                   expansions. Our model outperforms competitive baselines on
                   the PersonaChat dataset in terms of dialog quality and
                   diversity while achieving persona-consistent and
                   controllable dialog generation.",
  month         =  oct,
  year          =  2020,
  keywords      = "commonsense reasoning;need to include in proposal
                   outline;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2010.03205"
}

@ARTICLE{Zhou2021-or,
  title         = "{Commonsense-Focused} Dialogues for Response Generation: An
                   Empirical Study",
  author        = "Zhou, Pei and Gopalakrishnan, Karthik and Hedayatnia, Behnam
                   and Kim, Seokhwan and Pujara, Jay and Ren, Xiang and Liu,
                   Yang and Hakkani-Tur, Dilek",
  abstract      = "Smooth and effective communication requires the ability to
                   perform latent or explicit commonsense inference. Prior
                   commonsense reasoning benchmarks (such as SocialIQA and
                   CommonsenseQA) mainly focus on the discriminative task of
                   choosing the right answer from a set of candidates, and do
                   not involve interactive language generation as in dialogue.
                   Moreover, existing dialogue datasets do not explicitly focus
                   on exhibiting commonsense as a facet. In this paper, we
                   present an empirical study of commonsense in dialogue
                   response generation. We first auto-extract commonsensical
                   dialogues from existing dialogue datasets by leveraging
                   ConceptNet, a commonsense knowledge graph. Furthermore,
                   building on social contexts/situations in SocialIQA, we
                   collect a new dialogue dataset with 25K dialogues aimed at
                   exhibiting social commonsense in an interactive setting. We
                   evaluate response generation models trained using these
                   datasets and find that models trained on both extracted and
                   our collected data produce responses that consistently
                   exhibit more commonsense than baselines. Finally we propose
                   an approach for automatic evaluation of commonsense that
                   relies on features derived from ConceptNet and pre-trained
                   language and dialog models, and show reasonable correlation
                   with human evaluation of responses' commonsense quality. We
                   are releasing a subset of our collected data,
                   Commonsense-Dialogues, containing about 11K dialogs.",
  month         =  sep,
  year          =  2021,
  keywords      = "dataset;commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2109.06427"
}

@ARTICLE{Zhang2018-st,
  title         = "Personalizing Dialogue Agents: {I} have a dog, do you have
                   pets too?",
  author        = "Zhang, Saizheng and Dinan, Emily and Urbanek, Jack and
                   Szlam, Arthur and Kiela, Douwe and Weston, Jason",
  abstract      = "Chit-chat models are known to have several problems: they
                   lack specificity, do not display a consistent personality
                   and are often not very captivating. In this work we present
                   the task of making chit-chat more engaging by conditioning
                   on profile information. We collect data and train models to
                   (i) condition on their given profile information; and (ii)
                   information about the person they are talking to, resulting
                   in improved dialogues, as measured by next utterance
                   prediction. Since (ii) is initially unknown our model is
                   trained to engage its partner with personal topics, and we
                   show the resulting dialogue can be used to predict profile
                   information about the interlocutors.",
  month         =  jan,
  year          =  2018,
  keywords      = "dataset;need to include in proposal outline;thesis/prior
                   work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "1801.07243"
}

@ARTICLE{Choi2018-yk,
  title         = "{QuAC} : Question Answering in Context",
  author        = "Choi, Eunsol and He, He and Iyyer, Mohit and Yatskar, Mark
                   and Yih, Wen-Tau and Choi, Yejin and Liang, Percy and
                   Zettlemoyer, Luke",
  abstract      = "We present QuAC, a dataset for Question Answering in Context
                   that contains 14K information-seeking QA dialogs (100K
                   questions in total). The dialogs involve two crowd workers:
                   (1) a student who poses a sequence of freeform questions to
                   learn as much as possible about a hidden Wikipedia text, and
                   (2) a teacher who answers the questions by providing short
                   excerpts from the text. QuAC introduces challenges not found
                   in existing machine comprehension datasets: its questions
                   are often more open-ended, unanswerable, or only meaningful
                   within the dialog context, as we show in a detailed
                   qualitative evaluation. We also report results for a number
                   of reference models, including a recently state-of-the-art
                   reading comprehension architecture extended to model dialog
                   context. Our best model underperforms humans by 20 F1,
                   suggesting that there is significant room for future work on
                   this data. Dataset, baseline, and leaderboard available at
                   http://quac.ai.",
  month         =  aug,
  year          =  2018,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1808.07036"
}

@ARTICLE{Reddy2018-bq,
  title         = "{CoQA}: A Conversational Question Answering Challenge",
  author        = "Reddy, Siva and Chen, Danqi and Manning, Christopher D",
  abstract      = "Humans gather information by engaging in conversations
                   involving a series of interconnected questions and answers.
                   For machines to assist in information gathering, it is
                   therefore essential to enable them to answer conversational
                   questions. We introduce CoQA, a novel dataset for building
                   Conversational Question Answering systems. Our dataset
                   contains 127k questions with answers, obtained from 8k
                   conversations about text passages from seven diverse
                   domains. The questions are conversational, and the answers
                   are free-form text with their corresponding evidence
                   highlighted in the passage. We analyze CoQA in depth and
                   show that conversational questions have challenging
                   phenomena not present in existing reading comprehension
                   datasets, e.g., coreference and pragmatic reasoning. We
                   evaluate strong conversational and reading comprehension
                   models on CoQA. The best system obtains an F1 score of
                   65.4\%, which is 23.4 points behind human performance
                   (88.8\%), indicating there is ample room for improvement. We
                   launch CoQA as a challenge to the community at
                   http://stanfordnlp.github.io/coqa/",
  month         =  aug,
  year          =  2018,
  keywords      = "dataset;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "1808.07042"
}

@ARTICLE{Richardson2023-mq,
  title         = "Commonsense Reasoning for Conversational {AI}: A Survey of
                   the State of the Art",
  author        = "Richardson, Christopher and Heck, Larry",
  abstract      = "Large, transformer-based pretrained language models like
                   BERT, GPT, and T5 have demonstrated a deep understanding of
                   contextual semantics and language syntax. Their success has
                   enabled significant advances in conversational AI, including
                   the development of open-dialogue systems capable of
                   coherent, salient conversations which can answer questions,
                   chat casually, and complete tasks. However, state-of-the-art
                   models still struggle with tasks that involve higher levels
                   of reasoning - including commonsense reasoning that humans
                   find trivial. This paper presents a survey of recent
                   conversational AI research focused on commonsense reasoning.
                   The paper lists relevant training datasets and describes the
                   primary approaches to include commonsense in conversational
                   AI. The paper also discusses benchmarks used for evaluating
                   commonsense in conversational AI problems. Finally, the
                   paper presents preliminary observations of the limited
                   commonsense capabilities of two state-of-the-art open
                   dialogue models, BlenderBot3 and LaMDA, and its negative
                   effect on natural interactions. These observations further
                   motivate research on commonsense reasoning in conversational
                   AI.",
  month         =  feb,
  year          =  2023,
  keywords      = "commonsense reasoning;thesis/prior work",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2302.07926"
}
